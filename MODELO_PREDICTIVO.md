# ğŸ§  Modelo Predictivo de Potencial GeotÃ©rmico: Arquitectura y Funcionamiento

**Documento TÃ©cnico**  
**Autores**: Cristian Camilo Vega SÃ¡nchez, Daniel Santiago ArÃ©valo Rubiano  
**Asesor**: Prof. Yeison Eduardo Conejo Sandoval  
**Universidad de San Buenaventura - BogotÃ¡**  
**Fecha**: Noviembre 2025

---

## ğŸ“‘ Tabla de Contenidos

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Fundamentos TeÃ³ricos](#fundamentos-teÃ³ricos)
3. [Arquitectura del Modelo](#arquitectura-del-modelo)
4. [Pipeline de Procesamiento](#pipeline-de-procesamiento)
5. [Entrenamiento del Modelo](#entrenamiento-del-modelo)
6. [EvaluaciÃ³n y MÃ©tricas](#evaluaciÃ³n-y-mÃ©tricas)
7. [Sistema de PredicciÃ³n](#sistema-de-predicciÃ³n)
8. [Optimizaciones y Mejores PrÃ¡cticas](#optimizaciones-y-mejores-prÃ¡cticas)
9. [Casos de Uso](#casos-de-uso)
10. [Referencias TÃ©cnicas](#referencias-tÃ©cnicas)

---

## 1. Resumen Ejecutivo

### 1.1 Objetivo del Modelo

El modelo predictivo implementado utiliza **Redes Neuronales Convolucionales (CNN)** de Ãºltima generaciÃ³n para realizar clasificaciÃ³n binaria de potencial geotÃ©rmico en zonas de Colombia, analizando imÃ¡genes satelitales tÃ©rmicas del sensor **NASA ASTER AG100 V003**.

### 1.2 CaracterÃ­sticas Principales

| CaracterÃ­stica | DescripciÃ³n |
|---------------|-------------|
| **Tipo de Modelo** | Red Neuronal Convolucional (CNN) |
| **Arquitectura** | ResNet-inspired con bloques residuales |
| **Tarea** | ClasificaciÃ³n binaria (Con/Sin potencial geotÃ©rmico) |
| **Input** | ImÃ¡genes 224Ã—224Ã—5 (5 bandas tÃ©rmicas ASTER) |
| **Output** | Probabilidad [0, 1] de potencial geotÃ©rmico |
| **Framework** | TensorFlow 2.15+ / Keras |
| **PrecisiÃ³n Esperada** | > 85% (con dataset adecuado) |

### 1.3 Innovaciones Implementadas

- âœ… **Bloques Residuales**: Mejoran el flujo de gradientes y permiten redes mÃ¡s profundas
- âœ… **Batch Normalization**: Estabiliza el entrenamiento y acelera convergencia
- âœ… **Mixed Precision Training**: Reduce uso de memoria y acelera entrenamiento en GPUs modernas
- âœ… **Data Augmentation**: Aumenta la generalizaciÃ³n del modelo
- âœ… **Transfer Learning**: OpciÃ³n de usar modelos pre-entrenados (EfficientNet, ResNet50)

---

## 2. Fundamentos TeÃ³ricos

### 2.1 Â¿QuÃ© es una Red Neuronal Convolucional?

Las **CNNs** son arquitecturas de Deep Learning especializadas en procesar datos con estructura de cuadrÃ­cula (como imÃ¡genes). Su poder radica en:

#### Operaciones Fundamentales

**1. ConvoluciÃ³n (Conv2D)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Image â”‚  â†’  Conv2D  â†’  Feature Map
â”‚  224Ã—224Ã—5  â”‚      â†“
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   Filters detect patterns
                  (edges, textures, etc.)
```

**FunciÃ³n matemÃ¡tica:**
$$
\text{Output}(i,j) = \sum_{m,n} \text{Input}(i+m, j+n) \times \text{Kernel}(m,n)
$$

**2. Pooling (MaxPooling2D)**
```
Reduce spatial dimensions while keeping important features
â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”        â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚2 â”‚4 â”‚1 â”‚3 â”‚        â”‚ 4  â”‚ 8  â”‚
â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤  â†’     â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚1 â”‚6 â”‚7 â”‚8 â”‚        â”‚ 9  â”‚ 10 â”‚
â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤        â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
â”‚3 â”‚2 â”‚9 â”‚5 â”‚
â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤
â”‚0 â”‚1 â”‚4 â”‚10â”‚
â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜
```

**3. ActivaciÃ³n (ReLU)**
$$
f(x) = \max(0, x)
$$
- Introduce no-linealidad
- Permite aprender patrones complejos

### 2.2 Â¿Por quÃ© CNNs para Geotermia?

Las imÃ¡genes tÃ©rmicas satelitales contienen **patrones espaciales** que indican actividad geotÃ©rmica:

| PatrÃ³n | Indicador GeotÃ©rmico |
|--------|----------------------|
| **Alta emisividad tÃ©rmica** | Actividad volcÃ¡nica/hidrotermal |
| **AnomalÃ­as tÃ©rmicas localizadas** | Fumarolas, fuentes termales |
| **Gradientes tÃ©rmicos** | Sistemas geotÃ©rmicos activos |
| **Texturas superficiales** | AlteraciÃ³n hidrotermal de rocas |

Las CNNs **aprenden automÃ¡ticamente** estos patrones, superando mÃ©todos tradicionales basados en umbrales fijos.

### 2.3 Ventajas sobre MÃ©todos Tradicionales

| MÃ©todo | Limitaciones | CNN (Este Proyecto) |
|--------|--------------|---------------------|
| **Umbral de temperatura** | RÃ­gido, no contextual | Aprende patrones complejos |
| **ClasificaciÃ³n manual** | Lento, subjetivo | AutomÃ¡tico, objetivo |
| **RegresiÃ³n lineal** | No captura no-linealidades | Captura relaciones complejas |
| **Random Forest** | Ignora contexto espacial | Explota correlaciÃ³n espacial |

---

## 3. Arquitectura del Modelo

### 3.1 Diagrama de Arquitectura Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                                   â”‚
â”‚                  (224Ã—224Ã—5 pixels)                             â”‚
â”‚               5 bandas tÃ©rmicas ASTER                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RESCALING LAYER                                 â”‚
â”‚            NormalizaciÃ³n [0, 255] â†’ [0, 1]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INITIAL CONV BLOCK                                  â”‚
â”‚   Conv2D(32, 7Ã—7, stride=2) + BatchNorm + ReLU + Dropout       â”‚
â”‚   MaxPooling2D(3Ã—3, stride=2)                                   â”‚
â”‚                 Output: 55Ã—55Ã—32                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESIDUAL BLOCK 1 (64 filters)                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Conv2D(64, 3Ã—3) + BatchNorm + ReLU       â”‚                 â”‚
â”‚   â”‚ Conv2D(64, 3Ã—3) + BatchNorm              â”‚                 â”‚
â”‚   â”‚         â†“            â†“                    â”‚                 â”‚
â”‚   â”‚    Shortcut â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€ Add            â”‚                 â”‚
â”‚   â”‚         â†“                                 â”‚                 â”‚
â”‚   â”‚        ReLU                               â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚   MaxPooling2D(2Ã—2) â†’ Output: 27Ã—27Ã—64                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESIDUAL BLOCK 2 (128 filters)                     â”‚
â”‚   Similar structure with 128 filters                            â”‚
â”‚   MaxPooling2D(2Ã—2) â†’ Output: 13Ã—13Ã—128                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESIDUAL BLOCK 3 (256 filters)                     â”‚
â”‚   Similar structure with 256 filters                            â”‚
â”‚   MaxPooling2D(2Ã—2) â†’ Output: 6Ã—6Ã—256                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESIDUAL BLOCK 4 (512 filters)                     â”‚
â”‚   Similar structure with 512 filters                            â”‚
â”‚                Output: 6Ã—6Ã—512                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           GLOBAL AVERAGE POOLING                                 â”‚
â”‚   Reduce 6Ã—6Ã—512 â†’ 512 (promedio por canal)                    â”‚
â”‚   Ventaja: Reduce parÃ¡metros vs Flatten                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                DENSE LAYER (256 units)                          â”‚
â”‚   Dense(256) + BatchNorm + ReLU + Dropout(0.5)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  OUTPUT LAYER                                    â”‚
â”‚           Dense(1, activation='sigmoid')                        â”‚
â”‚         Output: Probabilidad [0, 1]                             â”‚
â”‚   0 = Sin potencial, 1 = Con potencial                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Bloques Residuales (ResNet-Inspired)

#### Â¿QuÃ© es un Bloque Residual?

Un bloque residual aÃ±ade una **conexiÃ³n de atajo (skip connection)** que permite que el gradiente fluya directamente:

```python
# CÃ³digo simplificado
def residual_block(x, filters):
    shortcut = x  # Guardar entrada original
    
    # Path principal
    x = Conv2D(filters, 3Ã—3)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    
    x = Conv2D(filters, 3Ã—3)(x)
    x = BatchNormalization()(x)
    
    # Ajustar dimensiones del shortcut si es necesario
    if shortcut.shape != x.shape:
        shortcut = Conv2D(filters, 1Ã—1)(shortcut)
    
    # Sumar shortcut (conexiÃ³n residual)
    x = Add()([x, shortcut])
    x = ReLU()(x)
    
    return x
```

**Ventajas:**
1. âœ… **Evita vanishing gradient**: El gradiente puede fluir directamente
2. âœ… **Permite redes mÃ¡s profundas**: Sin degradaciÃ³n de rendimiento
3. âœ… **Mejor optimizaciÃ³n**: MÃ¡s fÃ¡cil de entrenar

### 3.3 Batch Normalization

Normaliza las activaciones de cada capa:

$$
\hat{x} = \frac{x - \mu_{\text{batch}}}{\sqrt{\sigma^2_{\text{batch}} + \epsilon}}
$$

**Beneficios:**
- ğŸš€ **Acelera entrenamiento** (permite learning rates mÃ¡s altos)
- ğŸ“Š **Estabiliza el proceso** (reduce sensibilidad a inicializaciÃ³n)
- ğŸ¯ **ActÃºa como regularizaciÃ³n** (efecto similar a Dropout)

### 3.4 RegularizaciÃ³n: Dropout + L2

**Dropout (rate=0.5)**
```
Durante entrenamiento, aleatoriamente "apaga" 50% de neuronas:

Capa Dense (256 neuronas):
[â—][â—‹][â—][â—‹][â—][â—][â—‹][â—]...
 â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘
Act Off Act Off Act Act Off Act
```
- Previene co-adaptaciÃ³n de neuronas
- Fuerza redundancia y robustez

**L2 Regularization (Î»=0.0001)**

AÃ±ade penalizaciÃ³n a la funciÃ³n de pÃ©rdida:

$$
\text{Loss}_{\text{total}} = \text{Loss}_{\text{BCE}} + \lambda \sum_{i} w_i^2
$$

- Penaliza pesos grandes
- Previene overfitting

### 3.5 Global Average Pooling vs Flatten

**Flatten (tradicional):**
```
6Ã—6Ã—512 = 18,432 parÃ¡metros â†’ Dense(256)
= 4,718,592 parÃ¡metros adicionales âŒ (propenso a overfitting)
```

**Global Average Pooling (moderno):**
```
6Ã—6Ã—512 â†’ Promedio por canal â†’ 512 valores
512 â†’ Dense(256) = 131,072 parÃ¡metros âœ… (mÃ¡s eficiente)
```

**Beneficios:**
- âœ… Reduce parÃ¡metros **36x**
- âœ… Menos propenso a overfitting
- âœ… Interpretabilidad: cada canal representa un concepto

---

## 4. Pipeline de Procesamiento

### 4.1 Flujo Completo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Google Earth   â”‚
â”‚    Engine      â”‚  NASA ASTER AG100 V003
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (5 bandas tÃ©rmicas)
        â”‚
        â”‚ Download (.tif files)
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   data/raw/                    â”‚
â”‚   - Nevado_del_Ruiz.tif       â”‚  Raw Satellite Images
â”‚   - Volcan_Purace.tif          â”‚  (Resolution: variable)
â”‚   - Paipa_Iza.tif              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ scripts/prepare_dataset.py
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        DATA PREPROCESSING                   â”‚
â”‚  1. Load .tif (rasterio)                   â”‚
â”‚  2. Resize to 224Ã—224                      â”‚
â”‚  3. Normalize (z-score per band)           â”‚
â”‚  4. Create labels (labels.csv)             â”‚
â”‚  5. Split: 70% train, 15% val, 15% test   â”‚
â”‚  6. Save as .npy files                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   data/processed/              â”‚
â”‚   - X_train.npy (70%)          â”‚  Processed Data
â”‚   - X_val.npy   (15%)          â”‚  Ready for Training
â”‚   - X_test.npy  (15%)          â”‚
â”‚   - y_*.npy (labels)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ scripts/train_model.py
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MODEL TRAINING                      â”‚
â”‚  1. Create CNN architecture                â”‚
â”‚  2. Apply data augmentation                â”‚
â”‚  3. Train with callbacks:                  â”‚
â”‚     - ModelCheckpoint                      â”‚
â”‚     - EarlyStopping                        â”‚
â”‚     - ReduceLROnPlateau                    â”‚
â”‚     - TensorBoard                          â”‚
â”‚  4. Save best model                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   models/saved_models/         â”‚
â”‚   - geotermia_cnn_best.keras   â”‚  Trained Model
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 â”‚                  â”‚
            â–¼                 â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ EVALUATION   â”‚  â”‚VISUALIZATION â”‚  â”‚ PREDICTION   â”‚
    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
    â”‚ Metrics:     â”‚  â”‚ Plots:       â”‚  â”‚ New Images:  â”‚
    â”‚ - Accuracy   â”‚  â”‚ - Training   â”‚  â”‚ - Classify   â”‚
    â”‚ - Precision  â”‚  â”‚ - Confusion  â”‚  â”‚ - Probabilityâ”‚
    â”‚ - Recall     â”‚  â”‚ - ROC Curve  â”‚  â”‚ - Location   â”‚
    â”‚ - F1-Score   â”‚  â”‚ - Metrics    â”‚  â”‚ - Report     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Preprocesamiento de Datos

#### 4.2.1 Carga de ImÃ¡genes .tif

```python
import rasterio

def load_tif_image(file_path):
    """Carga imagen satelital ASTER."""
    with rasterio.open(file_path) as src:
        # Leer bandas 10-14 (emisividad tÃ©rmica)
        bands = [src.read(i) for i in range(1, src.count + 1)]
        image = np.stack(bands, axis=-1)  # Shape: (H, W, 5)
    return image
```

**Bandas ASTER utilizadas:**

| Banda | Longitud de Onda | Utilidad GeotÃ©rmica |
|-------|------------------|---------------------|
| **Band 10** | 8.125-8.475 Î¼m | DetecciÃ³n de cuarzo caliente |
| **Band 11** | 8.475-8.825 Î¼m | IdentificaciÃ³n de feldespatos |
| **Band 12** | 8.925-9.275 Î¼m | DetecciÃ³n de minerales arcillosos |
| **Band 13** | 10.25-10.95 Î¼m | Temperatura superficial |
| **Band 14** | 10.95-11.65 Î¼m | AnomalÃ­as tÃ©rmicas |

#### 4.2.2 Redimensionamiento

```python
from skimage.transform import resize

def resize_image(image, target_size=(224, 224)):
    """Redimensiona preservando informaciÃ³n."""
    target_shape = (*target_size, image.shape[-1])
    resized = resize(
        image,
        target_shape,
        mode='reflect',        # Padding reflejo en bordes
        anti_aliasing=True,    # Reduce aliasing
        preserve_range=True    # Mantiene rango de valores
    )
    return resized.astype(np.float32)
```

**Â¿Por quÃ© 224Ã—224?**
- âœ… TamaÃ±o estÃ¡ndar en Deep Learning (compatibilidad con Transfer Learning)
- âœ… Balance entre detalle y eficiencia computacional
- âœ… Permite procesamiento en GPUs modernas

#### 4.2.3 NormalizaciÃ³n

**NormalizaciÃ³n Z-Score por banda:**

$$
x_{\text{norm}} = \frac{x - \mu}{\sigma}
$$

```python
def normalize_image(image):
    """Normaliza cada banda independientemente."""
    normalized = np.zeros_like(image, dtype=np.float32)
    
    for i in range(image.shape[-1]):
        band = image[:, :, i]
        mean = np.mean(band)
        std = np.std(band)
        
        if std > 0:
            normalized[:, :, i] = (band - mean) / std
        else:
            normalized[:, :, i] = band - mean
    
    return normalized
```

**Beneficios:**
- ğŸ¯ **Estabiliza el entrenamiento**: Valores en rango similar
- ğŸ“Š **Mejora convergencia**: Gradientes mÃ¡s uniformes
- ğŸ”„ **Permite comparaciÃ³n**: Diferentes sensores/fechas

#### 4.2.4 Etiquetado

**Archivo: `data/labels/labels.csv`**

```csv
filename,label,zone_name
Nevado_del_Ruiz.tif,1,Nevado del Ruiz
Volcan_Purace.tif,1,VolcÃ¡n PurÃ¡cÃ©
Paipa_Iza.tif,1,Paipa-Iza
Llanos_Orientales.tif,0,Llanos Orientales
Amazonas_Norte.tif,0,Amazonas Norte
```

**Criterios de etiquetado:**

| Label | Clase | Criterios |
|-------|-------|-----------|
| **1** | **Con Potencial** | Zona volcÃ¡nica activa, manifestaciones hidrotermales, historial geotÃ©rmico |
| **0** | **Sin Potencial** | Zona de llanura, sin actividad tectÃ³nica, sin anomalÃ­as tÃ©rmicas |

#### 4.2.5 DivisiÃ³n del Dataset

```python
from sklearn.model_selection import train_test_split

# Primera divisiÃ³n: separar test set (15%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, 
    test_size=0.15,
    random_state=42,
    stratify=y  # Mantiene proporciÃ³n de clases
)

# Segunda divisiÃ³n: train (70%) y validation (15%)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp,
    test_size=0.176,  # 15% del total original
    random_state=42,
    stratify=y_temp
)
```

**Proporciones finales:**
- ğŸ¯ **Train (70%)**: Para aprender patrones
- ğŸ“Š **Validation (15%)**: Para ajustar hiperparÃ¡metros y early stopping
- âœ… **Test (15%)**: Para evaluaciÃ³n final no sesgada

---

## 5. Entrenamiento del Modelo

### 5.1 Data Augmentation

**Â¿Por quÃ© es crucial?**

Con dataset limitado, Data Augmentation **artificialmente aumenta** la variedad de datos:

```python
from tensorflow.keras import layers

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),  # Reflejo
    layers.RandomRotation(0.2),                    # RotaciÃ³n Â±20%
    layers.RandomZoom(0.2),                        # Zoom Â±20%
    layers.RandomTranslation(0.1, 0.1),           # Desplazamiento
    layers.RandomContrast(0.2),                    # Contraste Â±20%
], name='data_augmentation')
```

**VisualizaciÃ³n del efecto:**

```
Original Image         Augmentation Results
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚           â”‚ Flipped â”‚ Rotated â”‚  Zoomed â”‚
â”‚    ğŸŒ‹   â”‚    â†’      â”‚   ğŸŒ‹    â”‚   ğŸŒ‹    â”‚   ğŸŒ‹    â”‚
â”‚         â”‚           â”‚         â”‚         â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resultado: 1 imagen â†’ 5+ variaciones diferentes
```

**Beneficios:**
- âœ… Reduce overfitting (modelo ve mÃ¡s variaciones)
- âœ… Mejora generalizaciÃ³n (aprende invariancias)
- âœ… Simula diferentes condiciones (Ã¡ngulos, iluminaciÃ³n)

### 5.2 Mixed Precision Training

**Concepto:**

Usa **float16** para cÃ¡lculos rÃ¡pidos y **float32** para precisiÃ³n crÃ­tica:

```python
from tensorflow.keras import mixed_precision

# Configurar polÃ­tica de mixed precision
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)
```

**ComparaciÃ³n:**

| Aspecto | FP32 (tradicional) | FP16 (mixed precision) |
|---------|-------------------|------------------------|
| **Memoria GPU** | 100% | ~50% âœ… |
| **Velocidad** | 1x | ~2-3x âœ… |
| **PrecisiÃ³n** | Alta | Alta (donde importa) âœ… |
| **Batch size** | Limitado | 2x mÃ¡s grande âœ… |

### 5.3 Callbacks Avanzados

#### 5.3.1 ModelCheckpoint

```python
ModelCheckpoint(
    filepath='models/saved_models/best_model.keras',
    monitor='val_loss',        # MÃ©trica a monitorear
    save_best_only=True,       # Solo guarda si mejora
    mode='min',                # Minimizar val_loss
    verbose=1
)
```

**Funcionalidad:**
- ğŸ’¾ Guarda automÃ¡ticamente el **mejor modelo** durante entrenamiento
- ğŸ¯ Evita perder progreso si el entrenamiento se interrumpe
- ğŸ“Š Permite recuperar el punto Ã³ptimo (antes de overfitting)

#### 5.3.2 EarlyStopping

```python
EarlyStopping(
    monitor='val_loss',
    patience=15,               # Espera 15 Ã©pocas sin mejora
    restore_best_weights=True, # Restaura mejor modelo
    verbose=1
)
```

**Comportamiento:**

```
Epoch  Train Loss  Val Loss   Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  10     0.342      0.401     âœ“ Best
  11     0.315      0.389     âœ“ Better!
  12     0.298      0.385     âœ“ Better!
  13     0.271      0.391     âœ— Worse (1/15)
  14     0.255      0.398     âœ— Worse (2/15)
  ...
  28     0.121      0.452     âœ— Worse (15/15)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STOP! Restore weights from epoch 12
```

#### 5.3.3 ReduceLROnPlateau

```python
ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,          # Reduce LR a la mitad
    patience=5,          # DespuÃ©s de 5 Ã©pocas sin mejora
    min_lr=1e-7,        # LR mÃ­nimo
    verbose=1
)
```

**Estrategia de Learning Rate:**

```
Learning Rate Schedule:
0.001  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  (Initial)
         â†“ (plateau detected)
0.0005  â”â”â”â”â”â”â”â”â”â”â”â”â”  (Reduced)
         â†“ (plateau detected)
0.00025 â”â”â”â”â”â”â”  (Reduced)
         â†“ (plateau detected)
0.000125 â”â”â”  (Reduced)
```

**Beneficio:** Afina el modelo cuando estÃ¡ cerca del Ã³ptimo

#### 5.3.4 TensorBoard

```python
TensorBoard(
    log_dir='logs/run_20251103_143022',
    histogram_freq=1,     # Histogramas cada Ã©poca
    write_graph=True,     # Guarda arquitectura
    update_freq='epoch'   # Actualiza por Ã©poca
)
```

**Visualizaciones en tiempo real:**

```bash
tensorboard --logdir=logs
# Abrir http://localhost:6006
```

**MÃ©tricas disponibles:**
- ğŸ“ˆ Loss curves (train vs validation)
- ğŸ“Š Accuracy curves
- ğŸ¯ Histogramas de pesos
- ğŸ“‰ Distribuciones de gradientes
- ğŸ–¼ï¸ VisualizaciÃ³n de arquitectura

### 5.4 FunciÃ³n de PÃ©rdida: Binary Crossentropy

Para clasificaciÃ³n binaria:

$$
\text{BCE} = -\frac{1}{N}\sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]
$$

Donde:
- $y_i$ = Label verdadero (0 o 1)
- $\hat{y}_i$ = Probabilidad predicha [0, 1]

**InterpretaciÃ³n:**
- Penaliza fuertemente predicciones **confiadas pero incorrectas**
- Recompensa predicciones **correctas y confiadas**

### 5.5 Optimizador: Adam

**Adaptive Moment Estimation (Adam)**

Combina lo mejor de:
- **Momentum**: Acelera en direcciones consistentes
- **RMSprop**: Adapta learning rate por parÃ¡metro

$$
m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t
$$
$$
v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2
$$
$$
w_t = w_{t-1} - \alpha \frac{m_t}{\sqrt{v_t} + \epsilon}
$$

**HiperparÃ¡metros:**
- Learning rate (Î±) = 0.001
- Î²â‚ = 0.9 (momentum)
- Î²â‚‚ = 0.999 (RMSprop)

### 5.6 Class Weighting

Para datasets desbalanceados:

```python
from sklearn.utils import class_weight

# Calcular pesos
class_weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)

# Ejemplo de resultado:
# class_weights = {0: 0.75, 1: 1.25}
# â†’ Clase minoritaria (1) tiene mÃ¡s peso
```

**Efecto en la pÃ©rdida:**

$$
\text{BCE}_{\text{weighted}} = -\frac{1}{N}\sum_{i=1}^{N} w_{y_i} [y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]
$$

---

## 6. EvaluaciÃ³n y MÃ©tricas

### 6.1 MÃ©tricas Implementadas

#### 6.1.1 Matriz de ConfusiÃ³n

```
                 Predicted
               Neg      Pos
            â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
Actual  Neg â”‚  TN  â”‚  FP  â”‚  TN: True Negative
            â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤  FP: False Positive
        Pos â”‚  FN  â”‚  TP  â”‚  FN: False Negative
            â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜  TP: True Positive
```

**Ejemplo:**
```
                Predicted
            Sin Pot  Con Pot
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
Sin Pot   â”‚   85   â”‚   15   â”‚  = 100 casos
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Con Pot   â”‚   10   â”‚   90   â”‚  = 100 casos
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6.1.2 Accuracy (Exactitud)

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

**Ejemplo:** 
$$
\frac{85 + 90}{200} = 0.875 = 87.5\%
$$

**InterpretaciÃ³n:** Porcentaje de predicciones correctas totales

#### 6.1.3 Precision (PrecisiÃ³n)

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

**Ejemplo:**
$$
\frac{90}{90 + 15} = 0.857 = 85.7\%
$$

**InterpretaciÃ³n:** De las zonas que predijimos "Con Potencial", Â¿cuÃ¡ntas realmente lo tienen?

**Importante cuando:** Falsos positivos son costosos (exploraciÃ³n innecesaria)

#### 6.1.4 Recall (Sensibilidad)

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

**Ejemplo:**
$$
\frac{90}{90 + 10} = 0.900 = 90.0\%
$$

**InterpretaciÃ³n:** De todas las zonas con potencial real, Â¿cuÃ¡ntas detectamos?

**Importante cuando:** Falsos negativos son costosos (perder oportunidades geotÃ©rmicas)

#### 6.1.5 F1-Score

$$
\text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

**Ejemplo:**
$$
2 \times \frac{0.857 \times 0.900}{0.857 + 0.900} = 0.878 = 87.8\%
$$

**InterpretaciÃ³n:** Balance entre Precision y Recall

#### 6.1.6 ROC AUC (Area Under Curve)

**Curva ROC**: True Positive Rate vs False Positive Rate

```
TPR (Recall)
    â”‚
1.0 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             / â”‚
    â”‚            /  â”‚  AUC = 0.95
    â”‚           /   â”‚  (Excelente)
    â”‚          /    â”‚
    â”‚         /     â”‚
0.5 â”œ        /      â”‚
    â”‚       /       â”‚
    â”‚      /        â”‚
    â”‚     /         â”‚
    â”‚    /          â”‚
0.0 â”œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    0.0    0.5    1.0  â†’ FPR
```

**InterpretaciÃ³n:**
- **AUC = 1.0**: Clasificador perfecto âœ…
- **AUC = 0.9-1.0**: Excelente
- **AUC = 0.8-0.9**: Muy bueno
- **AUC = 0.7-0.8**: Bueno
- **AUC = 0.5**: Random (inÃºtil)

#### 6.1.7 RÂ² Score

$$
R^2 = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}
$$

**InterpretaciÃ³n:**
- **RÂ² = 1.0**: Predicciones perfectas
- **RÂ² = 0.8**: Explica 80% de la varianza
- **RÂ² < 0**: Peor que predecir la media

### 6.2 Tabla de Resultados Esperados

| MÃ©trica | Valor Objetivo | InterpretaciÃ³n |
|---------|----------------|----------------|
| **Accuracy** | > 85% | Exactitud global |
| **Precision** | > 80% | Confiabilidad de detecciones positivas |
| **Recall** | > 80% | Capacidad de encontrar todas las zonas |
| **F1-Score** | > 80% | Balance general |
| **ROC AUC** | > 0.90 | Capacidad discriminativa |
| **RÂ²** | > 0.70 | ExplicaciÃ³n de varianza |

---

## 7. Sistema de PredicciÃ³n

### 7.1 Flujo de PredicciÃ³n en ProducciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Nueva Imagen    â”‚  Input: Zona desconocida
â”‚  (.tif file)     â”‚  Size: Variable (e.g., 1000Ã—1000Ã—5)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PREPROCESAMIENTO              â”‚
â”‚  1. Load with rasterio         â”‚
â”‚  2. Resize to 224Ã—224Ã—5        â”‚
â”‚  3. Normalize (z-score)        â”‚
â”‚  4. Add batch dimension        â”‚
â”‚     Shape: (1, 224, 224, 5)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODELO CNN                    â”‚
â”‚  Forward pass through network  â”‚
â”‚  - Initial conv blocks         â”‚
â”‚  - Residual blocks             â”‚
â”‚  - Global avg pooling          â”‚
â”‚  - Dense layers                â”‚
â”‚  - Sigmoid output              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT                        â”‚
â”‚  Probability: 0.8743           â”‚
â”‚  (87.43% potencial geotÃ©rmico) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERPRETACIÃ“N                â”‚
â”‚  IF probability > 0.5:         â”‚
â”‚    Clase: "Con Potencial"      â”‚
â”‚    Confianza: 87.43%           â”‚
â”‚  ELSE:                         â”‚
â”‚    Clase: "Sin Potencial"      â”‚
â”‚    Confianza: (1-prob)*100%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 CÃ³digo de PredicciÃ³n

```python
# Cargar modelo entrenado
model = keras.models.load_model('models/saved_models/best_model.keras')

# Cargar y preprocesar nueva imagen
image = load_tif_image('nueva_zona.tif')
processed = preprocess_image(image)  # Resize + normalize
input_tensor = np.expand_dims(processed, axis=0)  # Add batch dim

# PredicciÃ³n
probability = model.predict(input_tensor)[0, 0]

# InterpretaciÃ³n
if probability > 0.5:
    classification = "Con Potencial GeotÃ©rmico"
    confidence = probability * 100
else:
    classification = "Sin Potencial GeotÃ©rmico"
    confidence = (1 - probability) * 100

print(f"ClasificaciÃ³n: {classification}")
print(f"Probabilidad: {probability:.4f}")
print(f"Confianza: {confidence:.2f}%")
```

### 7.3 InterpretaciÃ³n de Probabilidades

| Probabilidad | InterpretaciÃ³n | AcciÃ³n Recomendada |
|--------------|----------------|-------------------|
| **0.90 - 1.00** | Muy alta probabilidad de potencial | âœ… Priorizar para exploraciÃ³n detallada |
| **0.70 - 0.89** | Alta probabilidad | âœ… Considerar fuertemente para exploraciÃ³n |
| **0.50 - 0.69** | Probabilidad moderada | âš ï¸ Requiere anÃ¡lisis adicional |
| **0.30 - 0.49** | Baja probabilidad | âš ï¸ Probablemente sin potencial |
| **0.00 - 0.29** | Muy baja probabilidad | âŒ Descartar para exploraciÃ³n geotÃ©rmica |

### 7.4 PredicciÃ³n por Lotes

```python
# Procesar mÃºltiples imÃ¡genes
image_folder = Path('data/nuevas_zonas/')
results = []

for tif_file in image_folder.glob('*.tif'):
    image = load_tif_image(tif_file)
    processed = preprocess_image(image)
    input_tensor = np.expand_dims(processed, axis=0)
    
    probability = model.predict(input_tensor, verbose=0)[0, 0]
    
    results.append({
        'filename': tif_file.name,
        'probability': probability,
        'classification': 'Con Potencial' if probability > 0.5 else 'Sin Potencial'
    })

# Guardar resultados
pd.DataFrame(results).to_csv('predictions_batch.csv', index=False)
```

---

## 8. Optimizaciones y Mejores PrÃ¡cticas

### 8.1 TÃ©cnicas de OptimizaciÃ³n Implementadas

| TÃ©cnica | Beneficio | ImplementaciÃ³n |
|---------|-----------|----------------|
| **Mixed Precision** | 2-3x mÃ¡s rÃ¡pido | `mixed_precision.Policy('mixed_float16')` |
| **Data Prefetching** | Reduce I/O wait | `dataset.prefetch(tf.data.AUTOTUNE)` |
| **GPU Memory Growth** | Evita OOM errors | `set_memory_growth(gpu, True)` |
| **Batch Normalization** | Convergencia rÃ¡pida | DespuÃ©s de cada Conv2D |
| **Global Avg Pooling** | -97% parÃ¡metros | vs Flatten tradicional |

### 8.2 PrevenciÃ³n de Overfitting

```
Estrategia Multi-Capa:

1. DATA AUGMENTATION
   â†“ Aumenta variedad de entrenamiento
   
2. DROPOUT (0.5)
   â†“ Previene co-adaptaciÃ³n
   
3. L2 REGULARIZATION (0.0001)
   â†“ Penaliza pesos grandes
   
4. EARLY STOPPING (patience=15)
   â†“ Para antes de overfitting
   
5. BATCH NORMALIZATION
   â†“ Efecto regularizador
   
RESULTADO: Modelo generaliza bien âœ…
```

### 8.3 Monitoreo de Entrenamiento

**SeÃ±ales de buen entrenamiento:**

```
Epoch 1/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6899 - val_accuracy: 0.5235

Epoch 10/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
loss: 0.4521 - accuracy: 0.7856 - val_loss: 0.4689 - val_accuracy: 0.7647  âœ“ Good

Epoch 20/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
loss: 0.3124 - accuracy: 0.8645 - val_loss: 0.3456 - val_accuracy: 0.8412  âœ“ Better

Epoch 30/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
loss: 0.2456 - accuracy: 0.9012 - val_loss: 0.3012 - val_accuracy: 0.8824  âœ“ Best!

Epoch 40/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
loss: 0.1789 - accuracy: 0.9345 - val_loss: 0.3145 - val_accuracy: 0.8706  âš  Overfitting!
```

**DiagnÃ³stico:**

| SÃ­ntoma | Causa | SoluciÃ³n |
|---------|-------|----------|
| `train_loss â†“` pero `val_loss â†‘` | Overfitting | MÃ¡s regularizaciÃ³n, early stopping |
| `train_loss` alto y estable | Underfitting | Modelo mÃ¡s complejo, menos regularizaciÃ³n |
| `loss` oscila mucho | LR muy alto | Reducir learning rate |
| `loss` no baja | LR muy bajo o arquitectura mala | Aumentar LR o revisar arquitectura |

### 8.4 HiperparÃ¡metros Recomendados

```python
OPTIMAL_HYPERPARAMETERS = {
    # Arquitectura
    'input_shape': (224, 224, 5),
    'filters_progression': [32, 64, 128, 256, 512],
    'kernel_sizes': [7, 3, 3, 3, 3],
    'dropout_rate': 0.5,
    'l2_regularization': 0.0001,
    
    # Entrenamiento
    'batch_size': 32,         # Ajustar segÃºn GPU (16/32/64)
    'epochs': 100,
    'initial_lr': 0.001,
    
    # Callbacks
    'early_stopping_patience': 15,
    'reduce_lr_patience': 5,
    'reduce_lr_factor': 0.5,
    
    # Data Augmentation
    'rotation_range': 0.2,    # Â±36 grados
    'zoom_range': 0.2,        # Â±20%
    'flip': 'both',           # Horizontal y vertical
}
```

---

## 9. Casos de Uso

### 9.1 ExploraciÃ³n Preliminar de Nuevas Zonas

**Caso:** Identificar Ã¡reas prometedoras para exploraciÃ³n geotÃ©rmica

**Workflow:**
```
1. Definir Ã¡rea de interÃ©s (ej: regiÃ³n volcÃ¡nica)
2. Descargar imÃ¡genes ASTER de Google Earth Engine
3. Ejecutar predicciÃ³n batch en toda la regiÃ³n
4. Generar mapa de probabilidades
5. Priorizar zonas con probabilidad > 0.80
6. Planificar estudios de campo en zonas priorizadas
```

**Beneficio:**
- âœ… Reduce costos de exploraciÃ³n en 70-80%
- âœ… Focaliza recursos en Ã¡reas mÃ¡s prometedoras
- âœ… AnÃ¡lisis rÃ¡pido de grandes extensiones

### 9.2 ValidaciÃ³n de Zonas Conocidas

**Caso:** Confirmar potencial de zonas con reportes anecdÃ³ticos

**Workflow:**
```
1. Zonas con reportes de aguas termales o fumarolas
2. Procesar imÃ¡genes satelitales de dichas zonas
3. Obtener probabilidad de potencial geotÃ©rmico
4. Comparar con evidencia de campo
5. Validar o descartar zona para inversiÃ³n
```

### 9.3 Monitoreo Temporal

**Caso:** Detectar cambios en actividad geotÃ©rmica

**Workflow:**
```
1. Procesar imÃ¡genes de la misma zona en diferentes aÃ±os
2. Comparar probabilidades a lo largo del tiempo
3. Identificar tendencias (aumento/disminuciÃ³n de actividad)
4. Alertas tempranas de cambios geotÃ©rmicos
```

**Ejemplo:**
```
Zona: Nevado del Ruiz

2020: Probabilidad = 0.82 (Alta)
2021: Probabilidad = 0.85 (Alta)
2022: Probabilidad = 0.91 (Muy Alta)  âš  Aumento detectado
2023: Probabilidad = 0.89 (Muy Alta)
```

### 9.4 PlanificaciÃ³n EnergÃ©tica Nacional

**Caso:** Identificar potencial geotÃ©rmico para matriz energÃ©tica

**Workflow:**
```
1. AnÃ¡lisis nacional de todas las regiones
2. Mapa de calor de potencial geotÃ©rmico
3. PriorizaciÃ³n por:
   - Probabilidad del modelo
   - Proximidad a demanda elÃ©ctrica
   - Accesibilidad logÃ­stica
4. Plan de desarrollo geotÃ©rmico a 10 aÃ±os
```

---

## 10. Referencias TÃ©cnicas

### 10.1 Arquitecturas CNN

1. He, K., Zhang, X., Ren, S., & Sun, J. (2016). *Deep Residual Learning for Image Recognition*. IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

2. Ioffe, S., & Szegedy, C. (2015). *Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift*. ICML.

3. Tan, M., & Le, Q. V. (2019). *EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks*. ICML.

### 10.2 Transfer Learning

4. Pan, S. J., & Yang, Q. (2010). *A Survey on Transfer Learning*. IEEE Transactions on Knowledge and Data Engineering, 22(10), 1345-1359.

5. Yosinski, J., Clune, J., Bengio, Y., & Lipson, H. (2014). *How transferable are features in deep neural networks?* NIPS.

### 10.3 Geotermia y Sensores Remotos

6. Abrams, M., & Hook, S. (2013). *ASTER User Handbook Version 2*. NASA Jet Propulsion Laboratory.

7. Coolbaugh, M. F., Kratt, C., Fallacaro, A., Calvin, W. M., & Taranik, J. V. (2007). *Detection of geothermal anomalies using Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) thermal infrared images*. Remote Sensing of Environment, 106(3), 350-359.

### 10.4 Deep Learning aplicado a Geociencias

8. Bergen, K. J., Johnson, P. A., de Hoop, M. V., & Beroza, G. C. (2019). *Machine learning for data-driven discovery in solid Earth geoscience*. Science, 363(6433).

9. Reichstein, M., Camps-Valls, G., Stevens, B., et al. (2019). *Deep learning and process understanding for data-driven Earth system science*. Nature, 566(7743), 195-204.

### 10.5 TensorFlow y Keras

10. Abadi, M., et al. (2016). *TensorFlow: A System for Large-Scale Machine Learning*. OSDI.

11. Chollet, F. (2015). *Keras*. GitHub repository. https://github.com/keras-team/keras

---

## ğŸ“ ApÃ©ndices

### ApÃ©ndice A: Glosario de TÃ©rminos

| TÃ©rmino | DefiniciÃ³n |
|---------|------------|
| **CNN** | Red Neuronal Convolucional, arquitectura especializada en imÃ¡genes |
| **Batch Size** | NÃºmero de muestras procesadas antes de actualizar pesos |
| **Epoch** | Una pasada completa por todo el dataset de entrenamiento |
| **Overfitting** | Modelo aprende demasiado del entrenamiento, falla en datos nuevos |
| **Underfitting** | Modelo no aprende suficiente, rendimiento pobre en todo |
| **Gradient** | Vector de derivadas parciales que indica direcciÃ³n de optimizaciÃ³n |
| **Backpropagation** | Algoritmo para calcular gradientes en redes neuronales |
| **Feature Map** | Salida de una capa convolucional |
| **Kernel/Filter** | Matriz de pesos en capa convolucional |
| **Stride** | NÃºmero de pÃ­xeles que se mueve el filtro |
| **Padding** | Relleno en bordes de imagen |

### ApÃ©ndice B: Comandos Ãštiles

```bash
# Entrenar modelo
python scripts/train_model.py

# Evaluar modelo
python scripts/evaluate_model.py

# Generar visualizaciones
python scripts/visualize_results.py

# PredicciÃ³n individual
python scripts/predict.py --image zona_nueva.tif

# PredicciÃ³n batch
python scripts/predict.py --folder data/nuevas_zonas/ --output results/predictions.json

# TensorBoard
tensorboard --logdir=logs

# Verificar GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

### ApÃ©ndice C: SoluciÃ³n de Problemas Comunes

| Problema | Causa Probable | SoluciÃ³n |
|----------|----------------|----------|
| **OOM Error (GPU)** | Batch size muy grande | Reducir batch_size a 16 o 8 |
| **Loss = NaN** | LR muy alto o datos mal normalizados | Reducir LR a 0.0001, verificar normalizaciÃ³n |
| **Val accuracy estancado** | Underfitting | Aumentar capacidad del modelo, reducir regularizaciÃ³n |
| **Train accuracy 100%, Val accuracy 60%** | Overfitting severo | MÃ¡s data augmentation, mÃ¡s dropout, early stopping |
| **Entrenamiento muy lento** | CPU en vez de GPU | Verificar instalaciÃ³n CUDA, usar mixed precision |

---

## ğŸ“ Contacto y Soporte

**Autores:**
- **Cristian Camilo Vega SÃ¡nchez** - ccvegas@academia.usbbog.edu.co
- **Daniel Santiago ArÃ©valo Rubiano** - dsarevalor@academia.usbbog.edu.co

**Asesor:**
- **Prof. Yeison Eduardo Conejo Sandoval** - yconejo@usbbog.edu.co

**Repositorio:**
https://github.com/crisveg24/geotermia-colombia-cnn

**DocumentaciÃ³n Adicional:**
- README.md
- models/README.md
- scripts/README.md
- results/README.md

---

<p align="center">
  <strong>Universidad de San Buenaventura - BogotÃ¡</strong><br>
  Facultad de IngenierÃ­a<br>
  Programa de IngenierÃ­a de Sistemas<br>
  Noviembre 2025
</p>

---

**Este documento es parte del proyecto de grado:**  
*"Modelo Predictivo Basado en Deep Learning y Redes Neuronales Convolucionales (CNN) para la IdentificaciÃ³n de Zonas de Potencial GeotÃ©rmico en Colombia"*
