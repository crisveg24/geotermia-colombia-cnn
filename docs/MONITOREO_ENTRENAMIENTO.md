# üìä GU√çA DE MONITOREO DEL ENTRENAMIENTO

**Fecha de inicio:** 3 de noviembre de 2025 - 18:50  
**Estado:** ‚úÖ Entrenamiento en progreso  
**Terminal ID:** f0d3a017-04e8-4240-b69c-c8ab613413c8  
**Correcci√≥n aplicada:** Rutas absolutas basadas en ubicaci√≥n del script

---

## üéØ INFORMACI√ìN DEL ENTRENAMIENTO

### Configuraci√≥n Actual
```yaml
Script: scripts/train_model.py
Dataset: 5,518 im√°genes ASTER procesadas
Training Set: 3,862 im√°genes (70%)
Validation Set: 828 im√°genes (15%)
Test Set: 828 im√°genes (15%)

Modelo:
  Arquitectura: CNN personalizada ResNet-inspired
  Capas: 52
  Par√°metros: 5,025,409
  Input Shape: (224, 224, 5)
  Output: Clasificaci√≥n binaria

Hardware:
  Modo: CPU con optimizaciones oneDNN
  Precision: Mixed precision (float16/float32)
  Python: 3.10.11
  TensorFlow: 2.20.0
```

### Hiperpar√°metros
```python
batch_size = 32
epochs = 100  # Con EarlyStopping
learning_rate = 0.001
optimizer = Adam
loss = binary_crossentropy
class_weights = {0: 2.2247, 1: 0.6450}
```

---

## ‚è±Ô∏è TIEMPO ESTIMADO

### C√°lculos Basados en Dataset
```
Im√°genes por √©poca: 3,862 training + 828 validation
Batch size: 32
Steps por √©poca: ~120 training + ~26 validation

Tiempo estimado por √©poca: 1-2 minutos en CPU
√âpocas esperadas: 30-50 (con EarlyStopping)
Tiempo total estimado: 2-3 horas
```

### Hitos Esperados
- ‚è±Ô∏è **20 min:** ~10 √©pocas completadas
- ‚è±Ô∏è **40 min:** ~20 √©pocas completadas
- ‚è±Ô∏è **1 hora:** ~30 √©pocas completadas
- ‚è±Ô∏è **2 horas:** ~50-70 √©pocas completadas
- ‚è±Ô∏è **2.5-3 horas:** Entrenamiento completo (EarlyStopping)

---

## üìà C√ìMO MONITOREAR EL PROGRESO

### Opci√≥n 1: Salida del Terminal (VS Code)
La salida del terminal mostrar√°:
```
Epoch 1/100
120/120 [==============================] - 85s 710ms/step - loss: 0.6543 - accuracy: 0.7234 - val_loss: 0.5432 - val_accuracy: 0.7823
Epoch 2/100
120/120 [==============================] - 82s 683ms/step - loss: 0.5234 - accuracy: 0.7856 - val_loss: 0.4987 - val_accuracy: 0.8145
...
```

**M√©tricas a observar:**
- `loss`: Error en training (debe disminuir)
- `accuracy`: Precisi√≥n en training (debe aumentar)
- `val_loss`: Error en validation (debe disminuir y ser similar a loss)
- `val_accuracy`: Precisi√≥n en validation (debe aumentar)

**Se√±ales de buen entrenamiento:**
- ‚úÖ Loss disminuye constantemente
- ‚úÖ Accuracy aumenta gradualmente
- ‚úÖ val_loss similar a loss (no overfitting)
- ‚úÖ val_accuracy cercana a accuracy

**Se√±ales de problemas:**
- ‚ö†Ô∏è val_loss aumenta mientras loss disminuye ‚Üí OVERFITTING
- ‚ö†Ô∏è Loss no disminuye ‚Üí Learning rate muy bajo o modelo estancado
- ‚ö†Ô∏è Loss explota (NaN) ‚Üí Learning rate muy alto

### Opci√≥n 2: TensorBoard (Recomendado)

**Iniciar TensorBoard:**
```powershell
# En una nueva terminal (Ctrl+Shift+`)
cd C:\Users\crsti\proyectos\g_earth_geotermia-proyect
C:/Users/crsti/proyectos/.venv/Scripts/python.exe -m tensorboard --logdir=logs/tensorboard
```

**Acceder:**
- Abre navegador en: http://localhost:6006
- Se actualizar√° autom√°ticamente cada 30 segundos

**Visualizaciones disponibles:**
- **SCALARS:** Gr√°ficos de loss y accuracy en tiempo real
- **GRAPHS:** Arquitectura del modelo
- **DISTRIBUTIONS:** Distribuci√≥n de pesos
- **HISTOGRAMS:** Histogramas de activaciones

### Opci√≥n 3: Archivo CSV de Historial

El entrenamiento genera un archivo CSV en tiempo real:
```
models/training_history.csv
```

Puedes abrirlo con Excel o pandas para ver:
```python
import pandas as pd
df = pd.read_csv('models/training_history.csv')
print(df.tail())  # √öltimas 5 √©pocas
```

Columnas:
- `epoch`: N√∫mero de √©poca
- `loss`: Error de entrenamiento
- `accuracy`: Precisi√≥n de entrenamiento
- `val_loss`: Error de validaci√≥n
- `val_accuracy`: Precisi√≥n de validaci√≥n
- `lr`: Learning rate actual (cambia con ReduceLROnPlateau)

---

## üîî CALLBACKS ACTIVOS

### 1. EarlyStopping
```python
patience = 15 √©pocas
monitor = 'val_loss'
restore_best_weights = True
```

**¬øQu√© hace?**
- Detiene el entrenamiento si `val_loss` no mejora por 15 √©pocas consecutivas
- Restaura autom√°ticamente los pesos del mejor modelo
- Previene desperdicio de tiempo en entrenamiento innecesario

**Mensaje esperado:**
```
Restoring model weights from the end of the best epoch: 35.
Epoch 50: early stopping
```

### 2. ModelCheckpoint
```python
filepath = 'models/best_model.keras'
monitor = 'val_loss'
save_best_only = True
```

**¬øQu√© hace?**
- Guarda el modelo cada vez que `val_loss` mejora
- Solo mantiene la mejor versi√≥n (sobrescribe anteriores)
- Garantiza que tendremos el mejor modelo al final

**Mensaje esperado:**
```
Epoch 12: val_loss improved from 0.4532 to 0.4321, saving model to models/best_model.keras
```

### 3. ReduceLROnPlateau
```python
factor = 0.5
patience = 5 √©pocas
monitor = 'val_loss'
min_lr = 0.00001
```

**¬øQu√© hace?**
- Reduce learning rate a la mitad si `val_loss` no mejora por 5 √©pocas
- Ayuda a refinar el aprendizaje en fases avanzadas
- M√≠nimo: 0.00001 (no baja m√°s)

**Mensaje esperado:**
```
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005
```

### 4. TensorBoard
```python
log_dir = 'logs/tensorboard/[timestamp]'
update_freq = 'epoch'
```

**¬øQu√© hace?**
- Registra m√©tricas cada √©poca
- Permite visualizaci√≥n en tiempo real
- Guarda gr√°ficos de arquitectura

### 5. CSVLogger
```python
filename = 'models/training_history.csv'
append = False
```

**¬øQu√© hace?**
- Guarda m√©tricas en CSV cada √©poca
- Permite an√°lisis posterior con pandas/Excel
- Backup independiente de TensorBoard

---

## üìÅ ARCHIVOS GENERADOS DURANTE ENTRENAMIENTO

### En `models/`
```
best_model.keras              - Mejor modelo guardado (se actualiza)
training_history.csv          - M√©tricas por √©poca (se actualiza)
```

### En `logs/tensorboard/`
```
[timestamp]/
  ‚îú‚îÄ‚îÄ train/
  ‚îÇ   ‚îî‚îÄ‚îÄ events.out.tfevents...    - M√©tricas de entrenamiento
  ‚îî‚îÄ‚îÄ validation/
      ‚îî‚îÄ‚îÄ events.out.tfevents...    - M√©tricas de validaci√≥n
```

---

## üö® SE√ëALES DE ALERTA

### Problemas Comunes y Soluciones

#### 1. Overfitting (Sobreajuste)
**S√≠ntomas:**
- `val_loss` aumenta mientras `loss` disminuye
- `val_accuracy` << `accuracy` (diferencia >10%)

**Causa:** Modelo memoriza training data
**Soluci√≥n autom√°tica:** EarlyStopping detendr√° el entrenamiento

#### 2. Underfitting (Subajuste)
**S√≠ntomas:**
- Tanto `loss` como `val_loss` se mantienen altos
- `accuracy` y `val_accuracy` < 75%

**Causa:** Modelo muy simple o LR muy bajo
**Soluci√≥n:** Ya se est√° usando modelo complejo, esperar m√°s √©pocas

#### 3. Loss Explosiva
**S√≠ntomas:**
- `loss` se vuelve NaN
- Accuracy baja a 0% o 100%

**Causa:** Learning rate muy alto
**Soluci√≥n autom√°tica:** ReduceLROnPlateau reducir√° LR

#### 4. Entrenamiento Muy Lento
**S√≠ntomas:**
- Cada √©poca toma >5 minutos

**Causa:** CPU sin optimizaciones o batch size muy grande
**Soluci√≥n:** Ya se est√°n usando optimizaciones oneDNN

---

## üéì INTERPRETACI√ìN DE RESULTADOS

### M√©tricas Objetivo
```
‚úÖ EXCELENTE:
   - accuracy > 90%
   - val_accuracy > 85%
   - val_loss < 0.3

‚úÖ BUENO:
   - accuracy > 85%
   - val_accuracy > 80%
   - val_loss < 0.4

‚ö†Ô∏è ACEPTABLE:
   - accuracy > 80%
   - val_accuracy > 75%
   - val_loss < 0.5

‚ùå NECESITA MEJORA:
   - accuracy < 80%
   - val_accuracy < 75%
   - val_loss > 0.5
```

### Balance Loss vs Accuracy
```
Ideal:
  loss ‚âà val_loss          ‚Üí Buen balance, no overfitting
  accuracy ‚âà val_accuracy  ‚Üí Generalizaci√≥n correcta

Overfitting:
  loss << val_loss         ‚Üí Modelo memoriza training
  accuracy >> val_accuracy ‚Üí No generaliza a nuevos datos

Underfitting:
  loss ‚âà val_loss ‚âà alto   ‚Üí Modelo muy simple
  accuracy ‚âà val_accuracy < 80% ‚Üí Capacidad insuficiente
```

---

## üîç COMANDOS √öTILES DURANTE ENTRENAMIENTO

### Ver progreso en tiempo real (PowerShell)
```powershell
# Ver √∫ltimas l√≠neas del CSV
Get-Content models/training_history.csv -Tail 5

# Ver tama√±o del modelo guardado
Get-ChildItem models/best_model.keras | Select-Object Name, Length, LastWriteTime

# Verificar que el proceso est√© corriendo
Get-Process python
```

### Monitorear recursos del sistema
```powershell
# CPU y memoria
Get-Process python | Select-Object CPU, WorkingSet, Name

# Uso de disco
Get-PSDrive C
```

### Si necesitas detener el entrenamiento
```
1. Presiona Ctrl+C en la terminal donde corre el entrenamiento
2. El modelo guardar√° autom√°ticamente el mejor checkpoint hasta ese momento
3. Puedes reanudar desde el mejor modelo guardado
```

---

## üìä AN√ÅLISIS POST-ENTRENAMIENTO

### Al Completarse el Entrenamiento

El script mostrar√° un resumen final:
```
===============================================
        TRAINING COMPLETED SUCCESSFULLY
===============================================
Best model saved at: models/best_model.keras
Training history saved at: models/training_history.json

Final Metrics:
  - Training Loss:        0.XXXX
  - Training Accuracy:    XX.XX%
  - Validation Loss:      0.XXXX
  - Validation Accuracy:  XX.XX%

Total Training Time:     XX:XX:XX
Total Epochs:            XX
Best Epoch:              XX
===============================================
```

### Archivos Finales Generados
```
models/
  ‚îú‚îÄ‚îÄ best_model.keras          - Modelo listo para usar (~20 MB)
  ‚îú‚îÄ‚îÄ training_history.json     - Historial completo
  ‚îî‚îÄ‚îÄ training_history.csv      - M√©tricas tabuladas

logs/
  ‚îî‚îÄ‚îÄ tensorboard/              - Logs completos
      ‚îî‚îÄ‚îÄ [timestamp]/
```

---

## ‚è≠Ô∏è PR√ìXIMOS PASOS DESPU√âS DEL ENTRENAMIENTO

1. **Evaluar en Test Set (10 min)**
   ```bash
   python scripts/evaluate_model.py
   ```
   - Calcula m√©tricas finales en 828 im√°genes de prueba
   - Genera matriz de confusi√≥n
   - Calcula ROC AUC, Precision, Recall, F1

2. **Generar Visualizaciones (10 min)**
   ```bash
   python scripts/visualize_results.py
   ```
   - Curvas de entrenamiento
   - Matriz de confusi√≥n (300 DPI)
   - Curva ROC
   - Predicciones de muestra

3. **Actualizar Documentaci√≥n (15 min)**
   - Agregar m√©tricas finales a README.md
   - Completar REGISTRO_PROCESO.md
   - Preparar presentaci√≥n de resultados

4. **Commit a GitHub (10 min)**
   ```bash
   git add models/ results/
   git commit -m "feat: Modelo CNN entrenado - Accuracy XX%"
   git push origin main
   ```

---

## üìû CONTACTO Y SOPORTE

**Si el entrenamiento se detiene o hay errores:**

1. Captura el mensaje de error completo
2. Verifica logs en `logs/tensorboard/`
3. Revisa `models/training_history.csv` para √∫ltima √©poca exitosa
4. Consulta con el equipo de desarrollo

**Desarrolladores:**
- Cristian Camilo Vega S√°nchez
- Daniel Santiago Ar√©valo Rubiano

**Asesor:**
- Prof. Yeison Eduardo Conejo Sandoval

---

**√öltima actualizaci√≥n:** 3 de noviembre de 2025 - 18:42  
**Estado:** üü¢ Entrenamiento en progreso  
**Revisi√≥n siguiente:** Al completar entrenamiento
