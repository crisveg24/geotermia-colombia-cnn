# üöÄ GU√çA PARA ENTRENAR EN OTRA M√ÅQUINA

**Fecha:** 9 de febrero de 2026  
**Branch:** `main`  
**Prop√≥sito:** Entrenar modelo CNN en m√°quina con mejor hardware

---

## üìã RESUMEN

Esta gu√≠a te permitir√°:
1. ‚úÖ Clonar el proyecto en otra m√°quina
2. ‚úÖ Descargar los datos desde Google Earth Engine
3. ‚úÖ Generar el dataset augmentado (5,518 im√°genes)
4. ‚úÖ Entrenar el modelo CNN completo (100 √©pocas)
5. ‚úÖ Subir el modelo entrenado de vuelta al repositorio

---

## üîß PRERREQUISITOS EN LA NUEVA M√ÅQUINA

### Hardware Recomendado
```
CPU: 8+ cores (o GPU NVIDIA con CUDA)
RAM: 16 GB m√≠nimo
Disco: 10 GB libres
SO: Windows 10/11, Linux, o macOS
```

### Software Necesario
```
‚úÖ Python 3.10 o 3.11
‚úÖ Git
‚úÖ Cuenta de Google Cloud (para Earth Engine)
```

---

## üì• PASO 1: CLONAR EL REPOSITORIO

### En la nueva m√°quina:

```bash
# Clonar el repositorio
git clone https://github.com/crisveg24/geotermia-colombia-cnn.git
cd geotermia-colombia-cnn

# Ver el estado
git status
```

---

## üêç PASO 2: CONFIGURAR ENTORNO PYTHON

### Crear entorno virtual:

**Windows:**
```powershell
python -m venv .venv
.venv\Scripts\activate
```

**Linux/macOS:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### Instalar dependencias:

```bash
# Actualizar pip
python -m pip install --upgrade pip

# Instalar todas las dependencias
pip install -r requirements.txt
```

**Tiempo estimado:** 5-10 minutos

---

## üåç PASO 3: CONFIGURAR GOOGLE EARTH ENGINE

### Autenticar Earth Engine:

```bash
python -c "import ee; ee.Authenticate()"
```

Esto abrir√° el navegador para autenticaci√≥n OAuth. Usa la misma cuenta de Google Cloud:
- **Proyecto:** `alpine-air-469115-f0` (My First Project)

**Nota:** Si ya autenticaste antes en la otra m√°quina, las credenciales est√°n en `~/.config/earthengine/`

---

## üìä PASO 4: DESCARGAR Y PREPARAR DATOS

### Opci√≥n A: Descargar Im√°genes Originales (Recomendado)

```bash
# Descargar 85 im√°genes ASTER desde Google Earth Engine (~5 min)
python scripts/download_dataset.py
```

**Output:**
- `data/raw/positive/` - 45 im√°genes (volcanes y termales)
- `data/raw/negative/` - 40 im√°genes (zonas control)
- `data/raw/labels.csv` - Etiquetas
- Total: ~2.5 MB

### Generar Dataset Augmentado:

```bash
# Augmentar a 5,518 im√°genes (~30 segundos)
python scripts/augment_full_dataset.py
```

**Output:**
- `data/augmented/positive/` - 4,278 im√°genes
- `data/augmented/negative/` - 1,240 im√°genes
- Total: ~1.24 GB

### Preparar para Entrenamiento:

```bash
# Procesar y normalizar im√°genes (~2 minutos)
python scripts/prepare_dataset.py
```

**Output:**
- `data/processed/X_train.npy` - 3,862 im√°genes training
- `data/processed/X_val.npy` - 828 im√°genes validation
- `data/processed/X_test.npy` - 828 im√°genes test
- `data/processed/y_*.npy` - Etiquetas correspondientes
- Total: ~2.5 GB

### Opci√≥n B: Copiar Datos desde Disco Externo (M√°s R√°pido)

Si tienes las im√°genes en un disco externo (USB, SSD), puedes configurar
el proyecto para leer directamente desde ah√≠ sin copiar nada:

```powershell
# Windows PowerShell ‚Äî indicar al proyecto d√≥nde est√°n los datos
$env:GEOTERMIA_DATA_ROOT = "D:\geotermia_datos"

# Verificar que detecta el disco
python config.py
```

Todos los scripts (`download_dataset.py`, `augment_full_dataset.py`, `prepare_dataset.py`,
`train_model.py`) respetar√°n esta variable y leer√°n/escribir√°n en el disco externo.

Alternativamente, si prefieres copiar los datos procesados al proyecto:

```bash
# Copiar carpeta completa data/processed/
# Desde USB o ubicaci√≥n compartida a:
# geotermia-colombia-cnn/data/processed/
```

Esto te ahorra ~35 minutos de procesamiento.

---

## üöÄ PASO 5: ENTRENAR EL MODELO

### Iniciar Entrenamiento:

```bash
python scripts/train_model.py
```

### Configuraci√≥n del Entrenamiento:

```yaml
√âpocas m√°ximas: 100
Batch size: 32
Learning rate: 0.001
Optimizer: Adam
Callbacks:
  - EarlyStopping (patience=15)
  - ModelCheckpoint (guarda mejor modelo)
  - ReduceLROnPlateau (ajusta LR)
  - TensorBoard (logs)
  - CSVLogger (CSV con m√©tricas)
```

### Tiempo Estimado por Hardware:

```
CPU (8 cores):        ~3-4 horas
CPU (16+ cores):      ~2-3 horas
GPU (NVIDIA RTX):     ~20-40 minutos
GPU (NVIDIA Tesla):   ~10-20 minutos
```

**Nota:** El tiempo real depende del EarlyStopping. Puede detenerse antes de 100 √©pocas.

### Monitorear el Progreso:

**Opci√≥n 1: Salida del Terminal**
```
Epoch 1/100
121/121 [======] - 85s - loss: 0.95 - accuracy: 0.65 - val_loss: 0.89 - val_accuracy: 0.70
...
```

**Opci√≥n 2: TensorBoard (Recomendado)**
```bash
# En otra terminal
tensorboard --logdir=logs
# Abrir: http://localhost:6006
```

**Opci√≥n 3: CSV**
```bash
# Ver √∫ltimas √©pocas
# Windows:
Get-Content logs\geotermia_cnn_custom_*.csv -Tail 5

# Linux/macOS:
tail -n 5 logs/geotermia_cnn_custom_*.csv
```

---

## üìÅ ARCHIVOS GENERADOS

Al finalizar el entrenamiento:

```
models/saved_models/
  ‚îî‚îÄ‚îÄ geotermia_cnn_custom_best.keras  (~19 MB)

logs/
  ‚îú‚îÄ‚îÄ geotermia_cnn_custom_*.csv       (m√©tricas por √©poca)
  ‚îî‚îÄ‚îÄ tensorboard/                     (logs completos)

models/
  ‚îú‚îÄ‚îÄ training_history.json            (historial completo)
  ‚îî‚îÄ‚îÄ training_history.csv             (backup)
```

---

## ‚¨ÜÔ∏è PASO 6: SUBIR MODELO ENTRENADO

### Verificar Tama√±o del Modelo:

```bash
# Windows:
Get-ChildItem models\saved_models\*.keras | Select-Object Name, Length

# Linux/macOS:
ls -lh models/saved_models/*.keras
```

### Si el modelo es < 100 MB (recomendado):

```bash
# Agregar modelo al git
git add models/saved_models/geotermia_cnn_custom_best.keras
git add models/training_history.json
git add logs/*.csv

# Commit
git commit -m "feat: Modelo CNN entrenado completamente - Accuracy XX.XX%"

# Push a develop
git push origin develop
```

### Si el modelo es > 100 MB:

**Opci√≥n 1: Git LFS (Large File Storage)**
```bash
# Instalar Git LFS
git lfs install

# Trackear archivos grandes
git lfs track "*.keras"
git add .gitattributes

# Commit y push normal
git add models/saved_models/*.keras
git commit -m "feat: Modelo CNN entrenado con Git LFS"
git push origin develop
```

**Opci√≥n 2: Google Drive / Dropbox**
```bash
# Subir modelo a Drive
# Agregar link al README o en un archivo MODELO_LINK.txt

git add MODELO_LINK.txt
git commit -m "feat: Modelo entrenado - Link en Drive"
git push origin develop
```

**Opci√≥n 3: Solo m√©tricas y logs**
```bash
# Agregar solo resultados, no el modelo
git add models/training_history.json
git add logs/*.csv
git add results/

git commit -m "feat: Resultados de entrenamiento completo"
git push origin develop

# Modelo se transfiere por otro medio
```

---

## üìä PASO 7: EVALUAR MODELO

```bash
# Evaluar en test set (828 im√°genes)
python scripts/evaluate_model.py
```

**Output:**
- `results/metrics/evaluation_metrics.json`
- `results/metrics/confusion_matrix.png`
- `results/metrics/roc_curve.png`

### Generar Visualizaciones:

```bash
python scripts/visualize_results.py
```

**Output:**
- `results/figures/training_history.png`
- `results/figures/sample_predictions.png`
- Todas las figuras en 300 DPI para tesis

### Subir Resultados:

```bash
git add results/
git commit -m "feat: Evaluaci√≥n completa del modelo - M√©tricas finales"
git push origin develop
```

---

## üîÑ PASO 8: MERGE A MAIN (En m√°quina original)

Cuando el entrenamiento est√© completo:

```bash
# En m√°quina original
git checkout main
git pull origin main

# Ver cambios en develop
git fetch origin develop
git log origin/develop

# Hacer merge
git merge develop

# O hacer Pull Request en GitHub para revisi√≥n

# Push a main
git push origin main

# Opcional: Eliminar rama develop
git branch -d develop
git push origin --delete develop
```

---

## üö® SOLUCI√ìN DE PROBLEMAS

### Error: "No module named 'tensorflow'"

```bash
pip install tensorflow==2.20.0
```

### Error: "No such file or directory: data/processed/"

```bash
# Ejecutar preparaci√≥n de datos primero
python scripts/prepare_dataset.py
```

### Error: "CUDA out of memory" (GPU)

Reducir batch size en `scripts/train_model.py`:
```python
batch_size = 16  # en lugar de 32
```

### Error: "ModuleNotFoundError: No module named 'rasterio'"

```bash
pip install rasterio
```

### Entrenamiento muy lento

**CPU:** Normal, espera 3-4 horas  
**GPU no detectada:**
```bash
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

---

## üìù CHECKLIST DE PASOS

```
‚ñ° Clonar repositorio y checkout develop
‚ñ° Crear y activar entorno virtual
‚ñ° Instalar requirements.txt
‚ñ° Autenticar Google Earth Engine
‚ñ° Descargar im√°genes originales (o copiar procesadas)
‚ñ° Augmentar dataset
‚ñ° Preparar dataset
‚ñ° Entrenar modelo (monitorear con TensorBoard)
‚ñ° Esperar a EarlyStopping o 100 √©pocas
‚ñ° Evaluar en test set
‚ñ° Generar visualizaciones
‚ñ° Commit y push modelo/resultados a develop
‚ñ° Merge develop ‚Üí main
‚ñ° Eliminar rama develop (opcional)
```

---

## üìä M√âTRICAS ESPERADAS

Basado en entrenamiento parcial (30 √©pocas):

| M√©trica | √âpoca 30 | Proyecci√≥n Final |
|---------|----------|------------------|
| **Accuracy** | 65.26% | 70-78% |
| **AUC** | 0.6252 | 0.80-0.90 |
| **Precision** | 84.61% | 85-90% |
| **Recall** | 68.27% | 75-85% |
| **F1-Score** | 75.54% | 80-87% |

---

## üéØ OBJETIVO FINAL

Al completar todos los pasos:

‚úÖ Modelo CNN entrenado completamente (100 √©pocas o early stop)  
‚úÖ M√©tricas finales calculadas en test set  
‚úÖ Visualizaciones de alta calidad (300 DPI)  
‚úÖ Modelo disponible en repositorio o Drive  
‚úÖ Documentaci√≥n completa actualizada  
‚úÖ Rama develop mergeada a main  

---

## üìû CONTACTO

**Si tienes problemas:**
1. Revisa la secci√≥n "Soluci√≥n de Problemas"
2. Consulta `RESUMEN_PROYECTO.md` (secci√≥n Gu√≠a de Monitoreo)
3. Revisa `ANALISIS_ENTRENAMIENTO.md`

**Desarrollador:**
- Cristian Camilo Vega S√°nchez
- GitHub: @crisveg24

---

**√öltima actualizaci√≥n:** 3 de noviembre de 2025  
**Estado:** Gu√≠a completa para entrenamiento en m√°quina externa  
**Tiempo total estimado:** 4-5 horas (incluyendo setup)
