# ğŸ¤– GUÃA PASO A PASO â€” Geotermia Colombia CNN

> **PropÃ³sito**: Este documento permite que **cualquier IA o persona** reproduzca
> el pipeline completo del proyecto: desde cero hasta un modelo entrenado y la
> interfaz Streamlit funcionando.
>
> **Ãšltima actualizaciÃ³n**: 9 de febrero de 2026  
> **Autores**: Cristian Vega, Daniel ArÃ©valo, Yuliet Espitia, Laura Rivera  
> **Universidad de San Buenaventura â€” BogotÃ¡**

---

## ğŸ“‹ ÃNDICE

1. [Requisitos previos](#1--requisitos-previos)
2. [Clonar el repositorio](#2--clonar-el-repositorio)
3. [Crear y activar entorno virtual](#3--crear-y-activar-entorno-virtual)
4. [Instalar dependencias](#4--instalar-dependencias)
5. [Configurar Google Earth Engine](#5--configurar-google-earth-engine)
6. [Configurar origen de datos (local vs disco externo)](#6--configurar-origen-de-datos)
7. [Descargar imÃ¡genes ASTER](#7--descargar-imÃ¡genes-aster)
8. [AugmentaciÃ³n de datos](#8--augmentaciÃ³n-de-datos)
9. [Preparar dataset (.npy)](#9--preparar-dataset)
10. [Entrenar el modelo CNN](#10--entrenar-el-modelo-cnn)
11. [Evaluar el modelo](#11--evaluar-el-modelo)
12. [Ejecutar la interfaz Streamlit](#12--ejecutar-la-interfaz-streamlit)
13. [SoluciÃ³n de problemas](#13--soluciÃ³n-de-problemas)

---

## 1 Â· Requisitos previos

| Componente      | VersiÃ³n mÃ­nima | Notas |
|-----------------|----------------|-------|
| Python          | 3.10.x         | 3.10 o 3.11. NO 3.12+ (compatibilidad TF) |
| pip             | 23+            | `python -m pip install --upgrade pip` |
| Git             | 2.x            | Para clonar el repo |
| Cuenta Google   | â€”              | Para Google Earth Engine |
| Espacio disco   | ~5 GB          | Dataset completo + modelo |
| GPU (opcional)  | NVIDIA + CUDA 12 | Acelera el entrenamiento. Sin GPU funciona en CPU |

---

## 2 Â· Clonar el repositorio

```bash
git clone https://github.com/crisveg24/geotermia-colombia-cnn.git
cd geotermia-colombia-cnn
```

---

## 3 Â· Crear y activar entorno virtual

### Windows (PowerShell)
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### Windows (CMD)
```cmd
python -m venv .venv
.venv\Scripts\activate.bat
```

### Linux / macOS
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Verificar**:
```bash
python --version        # Debe decir 3.10.x o 3.11.x
pip --version           # Debe apuntar al .venv
```

---

## 4 Â· Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

> âš ï¸ **IMPORTANTE**: Si vas a usar tambiÃ©n la interfaz Streamlit, instala estos
> paquetes adicionales (ya estÃ¡n contemplados pero aÃºn no estÃ¡n en requirements.txt):
>
> ```bash
> pip install streamlit streamlit-folium fpdf2
> ```

**Verificar TensorFlow**:
```bash
python -c "import tensorflow as tf; print(tf.__version__)"
# Debe imprimir 2.20.0 o superior
```

**Verificar GPU** (opcional):
```bash
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
# Si tienes GPU NVIDIA con CUDA â†’ mostrarÃ¡ la lista de GPUs
# Si no â†’ mostrarÃ¡ []  (usarÃ¡ CPU, mÃ¡s lento pero funcional)
```

---

## 5 Â· Configurar Google Earth Engine

Este paso solo es necesario si vas a **descargar** imÃ¡genes nuevas.
Si ya tienes las imÃ¡genes en un disco externo, salta al [paso 6](#6--configurar-origen-de-datos).

```bash
# 1. Autenticarse
python -c "import ee; ee.Authenticate()"
# Se abrirÃ¡ un navegador. Inicia sesiÃ³n con tu cuenta Google y copia el token.

# 2. Verificar
python -c "import ee; ee.Initialize(project='alpine-air-469115-f0'); print('OK')"
```

> **Nota**: El proyecto GCP es `alpine-air-469115-f0`. Si usas otro proyecto,
> edita la lÃ­nea correspondiente en `scripts/download_dataset.py`.

---

## 6 Â· Configurar origen de datos

### OpciÃ³n A â€” Datos locales (por defecto)

No necesitas hacer nada especial. Los scripts buscarÃ¡n las imÃ¡genes en:
```
geotermia-colombia-cnn/
    data/
        raw/positive/     â† .tif geotÃ©rmicos
        raw/negative/     â† .tif control
        augmented/        â† .tif aumentados
        processed/        â† .npy listos para entrenar
```

### OpciÃ³n B â€” Datos en disco duro externo (USB, SSD, etc.)

Esto es Ãºtil cuando:
- No tienes espacio en el equipo local
- Vas a entrenar en los computadores de la universidad
- Quieres transportar el dataset sin re-descargar (~5 GB)

**Estructura esperada en el disco externo:**
```
D:\geotermia_datos\         â† (o E:\, F:\, la letra que tenga tu disco)
    raw\
        positive\           â† archivos .tif descargados (zonas geotÃ©rmicas)
        negative\           â† archivos .tif descargados (zonas control)
        labels.csv
    augmented\
        positive\           â† .tif con augmentaciÃ³n
        negative\
        labels.csv
    processed\
        X_train.npy
        y_train.npy
        X_val.npy
        y_val.npy
        X_test.npy
        y_test.npy
        split_info.json
```

**Configurar la ruta** (elige UNA de estas opciones):

#### OpciÃ³n B.1 â€” Variable de entorno (recomendada)

```powershell
# Windows PowerShell (sesiÃ³n actual)
$env:GEOTERMIA_DATA_ROOT = "D:\geotermia_datos"

# Windows PowerShell (permanente para el usuario)
[Environment]::SetEnvironmentVariable("GEOTERMIA_DATA_ROOT", "D:\geotermia_datos", "User")
```

```bash
# Linux / macOS
export GEOTERMIA_DATA_ROOT="/media/usuario/disco_externo/geotermia_datos"
```

#### OpciÃ³n B.2 â€” Archivo .env en la raÃ­z del proyecto

Crea un archivo `.env` en la raÃ­z del proyecto:
```
GEOTERMIA_DATA_ROOT=D:\geotermia_datos
```

> ğŸ’¡ Los scripts leen esta variable automÃ¡ticamente desde `config.py`.

**Verificar configuraciÃ³n**:
```bash
python config.py
```

Esto imprimirÃ¡ un resumen mostrando:
- Si detectÃ³ el disco externo
- CuÃ¡ntas imÃ¡genes hay en cada carpeta
- Si faltan directorios

Ejemplo de salida:
```
============================================================
CONFIGURACIÃ“N DEL PROYECTO GEOTERMIA CNN
============================================================
  Fuente de datos : env $GEOTERMIA_DATA_ROOT
  Disco externo   : SÃ
  Data root       : D:\geotermia_datos
  
  âœ… raw/positive          â†’ 45 .tif, 0 .npy
  âœ… raw/negative          â†’ 43 .tif, 0 .npy
  âœ… augmented             â†’ 2728 .tif, 0 .npy
  âœ… processed             â†’ 0 .tif, 6 .npy
============================================================
```

### Preparar un disco externo con imÃ¡genes existentes

Si ya descargaste las imÃ¡genes en otro equipo:

```powershell
# 1. Crear estructura en el disco externo
mkdir D:\geotermia_datos\raw\positive
mkdir D:\geotermia_datos\raw\negative
mkdir D:\geotermia_datos\augmented\positive
mkdir D:\geotermia_datos\augmented\negative
mkdir D:\geotermia_datos\processed

# 2. Copiar imÃ¡genes desde el proyecto local
xcopy /E data\raw\positive D:\geotermia_datos\raw\positive\
xcopy /E data\raw\negative D:\geotermia_datos\raw\negative\
copy data\raw\labels.csv D:\geotermia_datos\raw\

# 3. Si ya tienes augmentados y procesados, copiarlos tambiÃ©n
xcopy /E data\augmented D:\geotermia_datos\augmented\
xcopy /E data\processed D:\geotermia_datos\processed\
```

---

## 7 Â· Descargar imÃ¡genes ASTER

> **Â¿Ya tienes las imÃ¡genes?** Si las tienes en un disco externo o en `data/raw/`,
> salta al [paso 8](#8--augmentaciÃ³n-de-datos).

```bash
python scripts/download_dataset.py
```

- Descarga ~88 imÃ¡genes ASTER GED (5 bandas tÃ©rmicas de emisividad)
- 45 zonas geotÃ©rmicas (volcanes: Ruiz, PuracÃ©, Galeras, Paipa-Iza, etc.)
- 43 zonas de control (Llanos, AmazonÃ­a, Costa Caribe, etc.)
- ResoluciÃ³n: 90 m/pixel, radio 5 km por zona
- Tiempo estimado: 15-30 minutos
- Requiere conexiÃ³n a internet y auth de Earth Engine

**Salida**:
```
data/raw/positive/   â† ~45 archivos .tif
data/raw/negative/   â† ~43 archivos .tif
data/raw/labels.csv  â† archivo de etiquetas
```

> Si configuraste `GEOTERMIA_DATA_ROOT`, las imÃ¡genes se guardarÃ¡n directamente 
> en el disco externo.

---

## 8 Â· AugmentaciÃ³n de datos

```bash
python scripts/augment_full_dataset.py
```

- Aplica 30 tÃ©cnicas de augmentaciÃ³n a cada imagen
- Genera ~31Ã— mÃ¡s imÃ¡genes (original + 30 variaciones)
- TÃ©cnicas: rotaciÃ³n, flip, brillo, contraste, ruido, blur, crop, combinaciones
- Tiempo estimado: 10-20 minutos

**Salida** (si ~88 originales):
```
data/augmented/positive/  â† ~1,395 archivos .tif
data/augmented/negative/  â† ~1,333 archivos .tif
data/augmented/labels.csv
```

---

## 9 Â· Preparar dataset

```bash
python scripts/prepare_dataset.py
```

- Carga todos los .tif de `data/augmented/`
- Redimensiona a 224Ã—224 pÃ­xeles
- Normaliza por banda (z-score: media=0, std=1)
- Divide en train/val/test (70/15/15, estratificado)
- Calcula pesos de clase para balanceo
- Tiempo estimado: 5-15 minutos

**Salida**:
```
data/processed/
    X_train.npy, y_train.npy    â† ~70% de las imÃ¡genes
    X_val.npy,   y_val.npy      â† ~15%
    X_test.npy,  y_test.npy     â† ~15%
    split_info.json              â† metadatos del split
```

> Los archivos .npy pueden ser **muy grandes** (~2-4 GB). Si usas disco externo,
> estos tambiÃ©n se guardarÃ¡n ahÃ­.

---

## 10 Â· Entrenar el modelo CNN

```bash
python scripts/train_model.py
```

### ConfiguraciÃ³n del entrenamiento

| ParÃ¡metro | Valor | Notas |
|-----------|-------|-------|
| Input shape | 224Ã—224Ã—5 | 5 bandas ASTER (emisividad tÃ©rmica) |
| Batch size | 32 | Reducir a 16 si hay poca RAM/VRAM |
| Ã‰pocas | 100 mÃ¡x | EarlyStopping con patience=15 |
| Optimizer | AdamW | lr=0.001, weight_decay=0.0001 |
| Label Smoothing | 0.1 | RegularizaciÃ³n |
| Mixed Precision | SÃ­ | float16 para GPU (auto-desactiva en CPU) |
| Data Augmentation | SÃ­ | RandomFlip, Rotation, Zoom, Translation, Contrast |

### Tiempo estimado

| Hardware | Tiempo por Ã©poca | Total (~30-50 Ã©pocas) |
|----------|-----------------|----------------------|
| CPU (i5/i7) | 3-5 min | 2-4 horas |
| GPU GTX 1060+ | 15-30 seg | 15-30 min |
| GPU RTX 3060+ | 5-15 seg | 5-15 min |

### Callbacks automÃ¡ticos

- **ModelCheckpoint**: Guarda el mejor modelo segÃºn `val_loss`
- **EarlyStopping**: Para si val_loss no mejora en 15 Ã©pocas
- **ReduceLROnPlateau**: Reduce learning rate si val_loss se estanca 5 Ã©pocas
- **TensorBoard**: Logs para visualizaciÃ³n
- **CSVLogger**: Historial en CSV

**Salida**:
```
models/saved_models/
    geotermia_cnn_custom_best.keras   â† mejor modelo (usar este)
    geotermia_cnn_custom_final.keras  â† modelo al final del entrenamiento
logs/
    history_custom.json               â† historial de mÃ©tricas
    training_YYYYMMDD_HHMMSS/         â† logs de TensorBoard
```

### Monitorear con TensorBoard (opcional)

```bash
tensorboard --logdir=logs
# Abrir http://localhost:6006 en el navegador
```

---

## 11 Â· Evaluar el modelo

```bash
python scripts/evaluate_model.py
```

- EvalÃºa el mejor modelo sobre el conjunto de test
- Genera matriz de confusiÃ³n, curvas ROC/PR, mÃ©tricas detalladas
- **Salida**: `results/` con grÃ¡ficas y mÃ©tricas

---

## 12 Â· Ejecutar la interfaz Streamlit

```bash
streamlit run app.py --server.headless true
```

- Abrir **http://localhost:8501** en el navegador
- 5 secciones: Inicio, PredicciÃ³n (mapa interactivo), MÃ©tricas, Arquitectura, Acerca de
- Permite ingresar coordenadas y obtener predicciÃ³n de potencial geotÃ©rmico

> Si el modelo no estÃ¡ entrenado, la app mostrarÃ¡ "Modelo no disponible" pero
> seguirÃ¡ funcionando con las demÃ¡s secciones.

---

## 13 Â· SoluciÃ³n de problemas

### Error: `No module named streamlit`
```bash
pip install streamlit streamlit-folium fpdf2
```

### Error: `Descriptors cannot be created directly` (protobuf)
```bash
pip install --upgrade tensorflow
# TF 2.20+ resuelve el conflicto con protobuf moderno
```

### Error: `CUDA_ERROR_NO_DEVICE`
TensorFlow no detecta la GPU. Verifica:
```bash
nvidia-smi            # Â¿EstÃ¡ la GPU activa?
nvcc --version        # Â¿CUDA instalado?
```
Si no tienes GPU, el modelo entrenarÃ¡ en CPU (mÃ¡s lento pero funcional).

### Error: `FileNotFoundError: X_train.npy`
No has preparado el dataset. Ejecuta primero:
```bash
python scripts/prepare_dataset.py
```

### Error: `No .tif files found`
No hay imÃ¡genes descargadas. Opciones:
1. Descarga con `python scripts/download_dataset.py`
2. O configura el disco externo: `$env:GEOTERMIA_DATA_ROOT = "D:\geotermia_datos"`

### Las imÃ¡genes estÃ¡n en el disco externo pero no las encuentra
Verifica:
```bash
python config.py
```
Si dice "local (data/)", la variable de entorno no estÃ¡ configurada.
AsegÃºrate de que la letra de unidad sea correcta (D:\, E:\, F:\...).

### Error: Earth Engine `Not signed up`
```bash
python -c "import ee; ee.Authenticate()"
```
Luego repite el paso 5.

### Entrenamiento muy lento en CPU
- Reducir `BATCH_SIZE` a 16 en `config.py`
- Reducir `EPOCHS` a 50
- Considerar entrenar en Google Colab con GPU gratuita

---

## ğŸ”„ FLUJO RÃPIDO (RESUMEN)

```bash
# 1. Setup
git clone https://github.com/crisveg24/geotermia-colombia-cnn.git
cd geotermia-colombia-cnn
python -m venv .venv && .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
pip install streamlit streamlit-folium fpdf2

# 2. (Opcional) Configurar disco externo
$env:GEOTERMIA_DATA_ROOT = "D:\geotermia_datos"

# 3. Verificar config
python config.py

# 4. Pipeline de datos (saltar si ya tienes los .npy)
python scripts/download_dataset.py        # ~30 min, requiere internet
python scripts/augment_full_dataset.py    # ~15 min
python scripts/prepare_dataset.py         # ~10 min

# 5. Entrenar
python scripts/train_model.py             # 15 min (GPU) / 3 hrs (CPU)

# 6. Interfaz
streamlit run app.py --server.headless true
# â†’ http://localhost:8501
```

---

## ğŸ“¦ ESTRUCTURA FINAL DEL PROYECTO

```
geotermia-colombia-cnn/
â”œâ”€â”€ config.py                  â† NUEVO: configuraciÃ³n centralizada
â”œâ”€â”€ app.py                     â† Interfaz web Streamlit
â”œâ”€â”€ requirements.txt           â† Dependencias Python
â”œâ”€â”€ setup.py                   â† Setup del proyecto
â”œâ”€â”€ README.md                  â† DocumentaciÃ³n principal
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py    â† Paso 7: descarga de imÃ¡genes
â”‚   â”œâ”€â”€ augment_full_dataset.pyâ† Paso 8: augmentaciÃ³n
â”‚   â”œâ”€â”€ prepare_dataset.py     â† Paso 9: preparaciÃ³n .npy
â”‚   â”œâ”€â”€ train_model.py         â† Paso 10: entrenamiento
â”‚   â”œâ”€â”€ evaluate_model.py      â† Paso 11: evaluaciÃ³n
â”‚   â”œâ”€â”€ predict.py             â† PredicciÃ³n individual
â”‚   â””â”€â”€ visualize_results.py   â† VisualizaciÃ³n de resultados
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cnn_geotermia.py       â† Arquitectura del modelo
â”‚   â””â”€â”€ saved_models/          â† Modelos entrenados (.keras)
â”‚
â”œâ”€â”€ data/                      â† (o disco externo si GEOTERMIA_DATA_ROOT)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ positive/          â† .tif zonas geotÃ©rmicas
â”‚   â”‚   â”œâ”€â”€ negative/          â† .tif zonas control
â”‚   â”‚   â””â”€â”€ labels.csv
â”‚   â”œâ”€â”€ augmented/             â† .tif aumentados
â”‚   â””â”€â”€ processed/             â† .npy listos para entrenar
â”‚
â”œâ”€â”€ docs/                      â† DocumentaciÃ³n del proyecto
â”œâ”€â”€ logs/                      â† TensorBoard + historial
â”œâ”€â”€ results/                   â† MÃ©tricas y grÃ¡ficas
â””â”€â”€ notebooks/                 â† Jupyter notebooks exploratorios
```
