# üìã REGISTRO DEL PROCESO DE DESARROLLO
## Sistema CNN para Identificaci√≥n de Zonas Geot√©rmicas en Colombia

**Proyecto:** Modelo Predictivo CNN - Geotermia Colombia  
**Instituci√≥n:** Universidad de San Buenaventura - Bogot√°  
**Autores:** Cristian Camilo Vega S√°nchez, Daniel Santiago Ar√©valo Rubiano, Yuliet Katerin Espitia Ayala, Laura Sophie Rivera Martin  
**Asesor:** Prof. Yeison Eduardo Conejo Sandoval  
**Fecha Inicio:** Noviembre 2025  
**Repositorio:** https://github.com/crisveg24/geotermia-colombia-cnn

---

## üìÖ CRONOGRAMA DE ACTIVIDADES

### **FASE 1: CONFIGURACI√ìN Y DOCUMENTACI√ìN (Completada)**
**Fecha:** 3 de noviembre de 2025

#### 1.1 Documentaci√≥n T√©cnica
- **Archivo creado:** `MODELO_PREDICTIVO.md` (2,700+ l√≠neas)
- **Contenido:**
  - Resumen ejecutivo del proyecto
  - Fundamentos te√≥ricos de CNNs
  - Arquitectura detallada del modelo (52 capas)
  - Pipeline de procesamiento
  - Estrategias de entrenamiento
  - M√©tricas de evaluaci√≥n con ecuaciones LaTeX
  - Sistema de predicci√≥n
  - Optimizaciones
  - Casos de uso para Colombia
  - 11 referencias acad√©micas
- **Commit:** `33343c8` - "docs: Agregar documento t√©cnico completo del modelo predictivo CNN"

#### 1.2 Herramientas de Visualizaci√≥n
- **Archivo creado:** `scripts/visualize_architecture.py` (483 l√≠neas)
- **Funcionalidad:**
  - Clase `ArchitectureVisualizer`
  - Generaci√≥n de diagramas de arquitectura (PNG 300 DPI)
  - Tablas LaTeX para tesis
  - Res√∫menes en JSON y TXT
  - Comparaci√≥n con transfer learning
- **Commit:** `71b4627` - "feat: Agregar script de visualizaci√≥n de arquitectura CNN"

---

### **FASE 2: CONFIGURACI√ìN DEL ENTORNO (Completada)**
**Fecha:** 3 de noviembre de 2025

#### 2.1 Instalaci√≥n de Dependencias
- **Python:** 3.10.11
- **Entorno virtual:** `.venv` en `C:/Users/crsti/proyectos/`
- **Librer√≠as instaladas:**
  ```
  TensorFlow: 2.20.0 (331.7 MB)
  Keras: 3.12.0
  scikit-learn: 1.7.2
  scikit-image: 0.25.2
  opencv-python: 4.12.0
  scipy: 1.15.3
  numpy: 2.2.6
  pandas: √∫ltima versi√≥n
  rasterio: para lectura de GeoTIFF
  earthengine-api: para Google Earth Engine
  ```

#### 2.2 Verificaci√≥n del Modelo
- **Modelo:** CNN personalizado con arquitectura ResNet-inspired
- **Par√°metros totales:** 5,025,409
- **Capas totales:** 52
- **Input shape:** (None, 224, 224, 5) - 5 bandas t√©rmicas ASTER
- **Output shape:** (None, 1) - clasificaci√≥n binaria con sigmoid
- **Caracter√≠sticas:** Batch normalization, dropout, mixed precision
- **Estado:** ‚úÖ Verificado y funcional

#### 2.3 Configuraci√≥n Hardware
- **CPU:** Optimizaciones oneDNN habilitadas
- **Instrucciones:** SSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA
- **GPU:** No disponible (modo CPU)
- **Modo:** Entrenamiento en CPU con precisi√≥n mixta

---

### **FASE 3: ADQUISICI√ìN DE DATOS (Completada)**
**Fecha:** 3 de noviembre de 2025

#### 3.1 Autenticaci√≥n Google Earth Engine
- **Proyecto Google Cloud:** `alpine-air-469115-f0` (My First Project)
- **M√©todo:** OAuth 2.0
- **Dataset:** NASA/ASTER_GED/AG100_003 (ASTER Global Emissivity Dataset)
- **Estado:** ‚úÖ Autenticado y operacional

#### 3.2 Descarga de Im√°genes Satelitales
- **Script:** `scripts/download_dataset.py`
- **Tiempo de ejecuci√≥n:** ~4 minutos
- **Im√°genes descargadas:** 85 im√°genes ASTER
  
  **Im√°genes Positivas (45):** Zonas con actividad geot√©rmica
  - Nevado del Ruiz: 5 ubicaciones (center, north, south, east, west)
  - Volc√°n Purac√©: 5 ubicaciones
  - Volc√°n Galeras: 5 ubicaciones
  - Paipa-Iza: 5 ubicaciones
  - Nevado del Tolima: 5 ubicaciones
  - Volc√°n Cumbal: 5 ubicaciones
  - Volc√°n Sotar√°: 5 ubicaciones
  - Volc√°n Azufral: 5 ubicaciones
  - Zonas termales: Manizales, Coconuco, Santa Rosa de Cabal, Herveo, Villa Mar√≠a
  
  **Im√°genes Negativas (40):** Zonas de control sin actividad volc√°nica
  - Llanos Orientales: 10 ubicaciones (Casanare, Arauca, Meta, Vichada)
  - Amazonas: 8 ubicaciones (Leticia, Puerto Nari√±o, Florencia, etc.)
  - Costa Caribe: 8 ubicaciones (Barranquilla, Santa Marta, etc.)
  - Zona Andina Oriental: 5 ubicaciones (Bucaramanga, C√∫cuta, etc.)
  - Valle del Cauca: 5 ubicaciones (Cali, Palmira, etc.)
  - Choc√≥: 2 ubicaciones (Quibd√≥, Bah√≠a Solano)

- **Tama√±o total:** 2.49 MB
- **Balance inicial:** 88.9% (45/85 positivas)
- **Formato:** GeoTIFF con 5 bandas t√©rmicas
- **Resoluci√≥n espacial:** Variable seg√∫n zona
- **Salida:** `data/raw/` con subdirectorios `positive/` y `negative/`

#### 3.3 Metadata Generada
- `data/raw/dataset_metadata.json`: Informaci√≥n del dataset
- `data/raw/dataset_images.csv`: Lista de im√°genes con coordenadas
- `data/raw/labels.csv`: Etiquetas binarias (0: negativo, 1: positivo)

---

### **FASE 4: AUGMENTACI√ìN DEL DATASET (Completada)**
**Fecha:** 3 de noviembre de 2025

#### 4.1 Prueba Inicial de Augmentaci√≥n
- **Script de prueba:** `scripts/augment_dataset.py`
- **Im√°genes de prueba:** 3 im√°genes originales
- **Resultado:** 93 im√°genes (31 por original)
- **Tiempo:** 0.83 segundos
- **Estado:** ‚úÖ Validaci√≥n exitosa

#### 4.2 Augmentaci√≥n Completa del Dataset
- **Script:** `scripts/augment_full_dataset.py` (350+ l√≠neas)
- **Clase:** `FullDatasetAugmenter`
- **Tiempo de ejecuci√≥n:** 27 segundos

**T√©cnicas de Augmentaci√≥n Aplicadas (30 por imagen):**

1. **Transformaciones Geom√©tricas:**
   - Rotaci√≥n 90¬∞ (rotation_90)
   - Rotaci√≥n 180¬∞ (rotation_180)
   - Rotaci√≥n 270¬∞ (rotation_270)
   - Rotaci√≥n 45¬∞ (rotation_45)
   - Rotaci√≥n -45¬∞ (rotation_neg45)
   - Flip horizontal (flip_horizontal)
   - Flip vertical (flip_vertical)

2. **Transformaciones de Intensidad:**
   - Brillo +20% (brightness_1.2)
   - Brillo -20% (brightness_0.8)
   - Contraste +30% (contrast_1.3)
   - Contraste -30% (contrast_0.7)

3. **T√©cnicas de Ruido y Suavizado:**
   - Ruido gaussiano peque√±o (noise_small)
   - Ruido gaussiano medio (noise_medium)
   - Desenfoque gaussiano ligero (blur_light)
   - Desenfoque gaussiano medio (blur_medium)

4. **Recorte:**
   - Crop 90% (crop_0.9)
   - Crop 85% (crop_0.85)

5. **Combinaciones Complejas (13 t√©cnicas):**
   - rot90_flip_h: Rotaci√≥n 90¬∞ + flip horizontal
   - rot180_bright: Rotaci√≥n 180¬∞ + brillo
   - flip_v_contrast: Flip vertical + contraste
   - rot45_noise: Rotaci√≥n 45¬∞ + ruido
   - crop_blur: Recorte + desenfoque
   - bright_blur: Brillo + desenfoque
   - contrast_noise: Contraste + ruido
   - rot90_crop: Rotaci√≥n 90¬∞ + recorte
   - rot180_contrast: Rotaci√≥n 180¬∞ + contraste
   - flip_h_bright: Flip horizontal + brillo
   - rot270_blur: Rotaci√≥n 270¬∞ + desenfoque
   - crop_contrast_noise: Recorte + contraste + ruido
   - rot45_bright_blur: Rotaci√≥n 45¬∞ + brillo + desenfoque

**Resultados de la Augmentaci√≥n:**
- **Input:** 85 im√°genes originales
- **Output:** 5,518 im√°genes totales
- **Distribuci√≥n:**
  - Positivas: 4,278 im√°genes (77.5%)
  - Negativas: 1,240 im√°genes (22.5%)
- **Tama√±o:** 1.24 GB (1,240.27 MB)
- **Ubicaci√≥n:** `data/augmented/positive/` y `data/augmented/negative/`

#### 4.3 Correcci√≥n de Metadata
- **Problema detectado:** Labels.csv sin subdirectorios en rutas
- **Script corrector:** `scripts/fix_labels.py`
- **Acci√≥n:** Actualizaci√≥n de 5,518 rutas con prefijos `positive/` o `negative/`
- **Resultado:** Labels.csv corregido para lectura correcta

---

### **FASE 5: PREPARACI√ìN DEL DATASET (Completada)**
**Fecha:** 3 de noviembre de 2025 - 18:33

#### 5.1 Procesamiento de Im√°genes
- **Script:** `scripts/prepare_dataset.py` (418 l√≠neas)
- **Clase:** `GeoDataPreparator`
- **Tiempo de procesamiento:** ~2 minutos (5,518 im√°genes)

**Correcciones Realizadas:**
1. Actualizaci√≥n de rutas por defecto:
   - `raw_data_path='data/augmented'` (antes: 'data/raw')
   - `labels_path='data/augmented'` (antes: 'data/labels')

2. Normalizaci√≥n de bandas espectrales:
   - Detecci√≥n autom√°tica de n√∫mero de bandas
   - Expansi√≥n a 5 bandas si < 5 (duplicaci√≥n de √∫ltima banda)
   - Recorte a 5 bandas si > 5 (tomar primeras 5)
   - Garantiza consistencia: todas las im√°genes tienen exactamente 5 bandas

**Procesamiento Aplicado:**
- Carga de im√°genes GeoTIFF con rasterio
- Redimensionamiento a 224x224 p√≠xeles
- Normalizaci√≥n de valores de p√≠xel (0-1)
- Preservaci√≥n de 5 bandas t√©rmicas ASTER

#### 5.2 Divisi√≥n del Dataset
- **Estrategia:** Estratificada para mantener proporci√≥n de clases
- **Random state:** 42 (reproducibilidad)

**Distribuci√≥n Final:**
```
Training Set:   3,862 im√°genes (70.0%)
  - Clase 0 (negativo): 868 im√°genes
  - Clase 1 (positivo): 2,994 im√°genes

Validation Set: 828 im√°genes (15.0%)
  - Clase 0 (negativo): 186 im√°genes
  - Clase 1 (positivo): 642 im√°genes

Test Set:       828 im√°genes (15.0%)
  - Clase 0 (negativo): 186 im√°genes
  - Clase 1 (positivo): 642 im√°genes

TOTAL:          5,518 im√°genes (100%)
```

#### 5.3 Pesos de Clase para Balanceo
**Objetivo:** Compensar desbalance entre clases durante entrenamiento

```python
Clase 0 (negativo): peso = 2.2247
Clase 1 (positivo): peso = 0.6450

C√°lculo: peso_clase = n_samples / (n_classes * n_samples_clase)
```

- Mayor peso a clase minoritaria (negativos)
- Menor peso a clase mayoritaria (positivos)
- Evita sesgo hacia clase dominante

#### 5.4 Archivos Generados
**Ubicaci√≥n:** `data/processed/`

```
X_train.npy      - Im√°genes de entrenamiento:  (3862, 224, 224, 5) ~1.5 GB
y_train.npy      - Etiquetas de entrenamiento: (3862,)

X_val.npy        - Im√°genes de validaci√≥n:     (828, 224, 224, 5)  ~320 MB
y_val.npy        - Etiquetas de validaci√≥n:    (828,)

X_test.npy       - Im√°genes de prueba:         (828, 224, 224, 5)  ~320 MB
y_test.npy       - Etiquetas de prueba:        (828,)

dataset_info.json - Metadata completa del dataset procesado
```

**Formato:** NumPy arrays con dtype=float32
**Acceso r√°pido:** Carga directa con `np.load()`

---

### **FASE 6: ENTRENAMIENTO DEL MODELO (En Progreso)**
**Fecha inicio:** 3 de noviembre de 2025 - 18:55:28  
**Estado actual:** Entrenamiento interrumpido tras 30 √©pocas exitosas  
**Progreso:** 30/100 √©pocas (30% completado)

#### 6.1 Configuraci√≥n del Entrenamiento
- **Script:** `scripts/train_model.py`
- **Modelo:** CNN personalizado (52 capas, 5,025,409 par√°metros)
- **Hardware:** CPU con optimizaciones oneDNN (SSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA)
- **Precision:** Mixed precision (float16/float32) - fallback a Eigen para DT_HALF
- **Tiempo real por √©poca:** ~117 segundos (1.95 minutos)
- **Tiempo total estimado:** 3.8 horas para 100 √©pocas

#### 6.2 Hiperpar√°metros
```python
Batch size:        32
√âpocas m√°ximas:    100
Learning rate:     0.001
Optimizer:         Adam
Loss function:     Binary Crossentropy
M√©tricas:          Accuracy, Precision, Recall, AUC
```

#### 6.3 Callbacks Configurados
1. **EarlyStopping:**
   - Monitor: validation loss
   - Patience: 15 √©pocas
   - Restaura mejores pesos

2. **ModelCheckpoint:**
   - Guarda mejor modelo seg√∫n val_loss
   - Formato: Keras (.keras)
   - Ubicaci√≥n: `models/best_model.keras`

3. **ReduceLROnPlateau:**
   - Reduce learning rate si no mejora
   - Factor: 0.5
   - Patience: 5 √©pocas

4. **TensorBoard:**
   - Logs de entrenamiento
   - Ubicaci√≥n: `logs/tensorboard/`
   - Visualizaci√≥n de m√©tricas en tiempo real

5. **CSVLogger:**
   - Registro de m√©tricas por √©poca
   - Archivo: `models/training_history.csv`

#### 6.4 Data Augmentation en Tiempo Real
**Aplicado solo durante entrenamiento:**
- Random rotation: ¬±10¬∞
- Random horizontal flip
- Random vertical flip
- Random zoom: ¬±10%
- Random brightness: ¬±10%

#### 6.5 Salidas Esperadas
```
models/
  ‚îú‚îÄ‚îÄ best_model.keras           - Mejor modelo guardado
  ‚îú‚îÄ‚îÄ training_history.json      - Historial completo
  ‚îî‚îÄ‚îÄ training_history.csv       - M√©tricas por √©poca

logs/
  ‚îî‚îÄ‚îÄ tensorboard/               - Logs para TensorBoard
      ‚îî‚îÄ‚îÄ [timestamp]/
```

#### 6.6 Resultados Parciales (√âpoca 30/100)
**Tiempo transcurrido:** ~59 minutos (30 √©pocas √ó 117 seg/√©poca)

**Progreso de M√©tricas:**

| √âpoca | Accuracy | AUC | Loss | Precision | Recall | Tiempo/√âpoca |
|-------|----------|-----|------|-----------|--------|--------------|
| 1 | 65.62% | 0.4481 | 0.9892 | - | - | 136s |
| 5 | 65.29% | 0.5265 | 0.9215 | - | - | 117s |
| 10 | 64.15% | 0.5634 | 0.9523 | - | - | 117s |
| 15 | 64.32% | 0.5819 | 0.9498 | - | - | 117s |
| 20 | 64.55% | 0.5944 | 0.9447 | - | - | 117s |
| 25 | 64.91% | 0.6104 | 0.9335 | - | - | 117s |
| 30 | 65.26% | 0.6252 | 0.9241 | 0.8461 | 0.6827 | 117s |

**An√°lisis de Tendencias:**
- ‚úÖ **Accuracy:** Mejora constante de 65.29% ‚Üí 65.26% (estable con ligera mejora)
- ‚úÖ **AUC:** Crecimiento sostenido de 0.4481 ‚Üí 0.6252 (+39.5%)
- ‚úÖ **Loss:** Disminuci√≥n saludable de 0.9892 ‚Üí 0.9241 (-6.6%)
- ‚úÖ **Precision:** 84.61% (excelente para √©poca 30)
- ‚úÖ **Recall:** 68.27% (bueno, espacio para mejora)
- ‚úÖ **Tiempo estabilizado:** ~117 seg/√©poca despu√©s de √©poca 5

**Observaciones:**
- No se detecta overfitting: m√©tricas mejoran consistentemente
- AUC muestra mejor progreso que accuracy (mejor discriminaci√≥n)
- Precision alta indica pocas falsas alarmas
- Recall moderado indica oportunidad de capturar m√°s positivos
- Tiempo por √©poca muy consistente (variaci√≥n < 1 segundo)

**Estado:** Entrenamiento interrumpido pero funcionando correctamente. Se puede reanudar.

---

### **FASE 7: EVALUACI√ìN DEL MODELO (Pendiente ‚Äî Requiere Entrenamiento Completo)**

#### 7.1 M√©tricas a Calcular
- **Script:** `scripts/evaluate_model.py`
- **Dataset:** Test set (828 im√°genes)

**M√©tricas Principales:**
1. **Accuracy:** Precisi√≥n general del modelo
2. **Precision:** TP / (TP + FP)
3. **Recall (Sensibilidad):** TP / (TP + FN)
4. **F1-Score:** Media arm√≥nica de precision y recall
5. **ROC AUC:** √Årea bajo la curva ROC
6. **R¬≤ Score:** Coeficiente de determinaci√≥n
7. **Confusion Matrix:** Matriz de confusi√≥n 2x2

#### 7.2 An√°lisis por Clase
- Precision, Recall, F1 para cada clase
- Support (n√∫mero de muestras)
- An√°lisis de falsos positivos y negativos

#### 7.3 Archivos de Salida
```
results/metrics/
  ‚îú‚îÄ‚îÄ evaluation_metrics.json    - Todas las m√©tricas
  ‚îú‚îÄ‚îÄ metrics_table.csv          - Tabla para tesis
  ‚îú‚îÄ‚îÄ confusion_matrix.png       - Visualizaci√≥n (300 DPI)
  ‚îî‚îÄ‚îÄ roc_curve.png              - Curva ROC (300 DPI)
```

---

### **FASE 8: VISUALIZACI√ìN DE RESULTADOS (Pendiente ‚Äî Requiere Entrenamiento Completo)**

#### 8.1 Gr√°ficos de Entrenamiento
- **Script:** `scripts/visualize_results.py`
- **Resoluci√≥n:** 300 DPI (calidad publicaci√≥n)

**Visualizaciones a Generar:**
1. **Training History:**
   - Loss (train vs validation)
   - Accuracy (train vs validation)
   - Formato: Curvas en misma figura

2. **Confusion Matrix:**
   - Heatmap con seaborn
   - Anotaciones de valores
   - Normalizada y sin normalizar

3. **ROC Curve:**
   - Curva ROC con AUC
   - L√≠nea diagonal de referencia
   - Threshold √≥ptimo marcado

4. **Predicciones de Muestra:**
   - Grid de im√°genes reales
   - Predicciones vs etiquetas verdaderas
   - Probabilidades de confianza

5. **Distribuci√≥n de Probabilidades:**
   - Histograma de predicciones
   - Separaci√≥n por clase real

#### 8.2 Archivos de Salida
```
results/figures/
  ‚îú‚îÄ‚îÄ training_history.png       - Curvas de entrenamiento
  ‚îú‚îÄ‚îÄ confusion_matrix.png       - Matriz de confusi√≥n
  ‚îú‚îÄ‚îÄ confusion_matrix_norm.png  - Matriz normalizada
  ‚îú‚îÄ‚îÄ roc_curve.png              - Curva ROC
  ‚îú‚îÄ‚îÄ sample_predictions.png     - Muestras de predicciones
  ‚îî‚îÄ‚îÄ probability_distribution.png - Distribuci√≥n de probabilidades
```

---

### **FASE 9: DOCUMENTACI√ìN FINAL (Pendiente ‚Äî Requiere Entrenamiento Completo)**

#### 9.1 Actualizaci√≥n de README
- Resultados finales del entrenamiento
- M√©tricas de performance
- Instrucciones de uso del modelo
- Ejemplos de predicci√≥n

#### 9.2 Documento de Resultados
- An√°lisis de m√©tricas
- Comparaci√≥n con objetivos
- Limitaciones del modelo
- Recomendaciones para mejoras

#### 9.3 Commit Final
```bash
git add models/best_model.keras
git add results/
git add README.md
git add REGISTRO_PROCESO.md
git commit -m "feat: Modelo CNN entrenado con m√©tricas completas"
git push origin main
```

---

### **FASE 10: RECUPERACI√ìN DEL REPOSITORIO Y VALIDACI√ìN DEL PIPELINE (Completada)**
**Fecha:** 5 de febrero de 2026

#### 10.1 Clonaci√≥n y Configuraci√≥n del Entorno
- **Situaci√≥n:** El repositorio local fue perdido; se recuper√≥ desde GitHub.
- **Acci√≥n:** Clonaci√≥n del repositorio desde `https://github.com/crisveg24/geotermia-colombia-cnn.git`.
- **Entorno virtual:** Creado en `C:/Users/crsti/proyectos/.venv` (Python 3.10.11).
- **Dependencias:** Instaladas desde `requirements.txt`.
- **Earth Engine:** Autenticado con proyecto `geotermia-col` (nuevo proyecto GCP).

#### 10.2 Validaci√≥n con Mini-Dataset
Para verificar que todo el pipeline funciona correctamente sin necesidad de descargar el dataset completo, se cre√≥ un flujo de validaci√≥n con un mini-dataset:

- **Descarga:** 20 im√°genes ASTER (10 geot√©rmicas + 10 control) mediante `scripts/miniprueba/download_mini_dataset.py`.
- **Preparaci√≥n:** Normalizaci√≥n a 224√ó224√ó5, divisi√≥n train/val/test con `prepare_mini_dataset.py`.
- **Entrenamiento:** Mini-modelo CNN de 6 √©pocas con `train_mini_model.py` ‚Äî accuracy ~67%.
- **Evaluaci√≥n:** M√©tricas b√°sicas calculadas con `evaluate_mini_model.py`.
- **Predicci√≥n:** Script `predict_images.py` ejecut√≥ predicciones sobre las 20 im√°genes.
- **Reporte PDF:** Generado con `generar_reporte_pdf.py` usando FPDF2.

**Resultado:** Pipeline validado end-to-end. Las predicciones del mini-modelo (52-56% de confianza, todo predicho como geot√©rmico) fueron las esperadas dado el tama√±o m√≠nimo del dataset de prueba.

**Archivos creados (organizados en `scripts/miniprueba/`):**
```
scripts/miniprueba/
‚îú‚îÄ‚îÄ download_mini_dataset.py      # Descarga 20 im√°genes de prueba
‚îú‚îÄ‚îÄ prepare_mini_dataset.py       # Prepara y divide el mini-dataset
‚îú‚îÄ‚îÄ train_mini_model.py           # Entrena modelo de validaci√≥n (6 √©pocas)
‚îú‚îÄ‚îÄ evaluate_mini_model.py        # Eval√∫a m√©tricas del mini-modelo
‚îú‚îÄ‚îÄ predict_images.py             # Ejecuta predicciones sobre im√°genes
‚îú‚îÄ‚îÄ generar_reporte_pdf.py        # Genera reporte PDF del experimento
‚îî‚îÄ‚îÄ README.md                     # Documentaci√≥n del mini-experimento
```

---

### **FASE 11: OPTIMIZACI√ìN DEL MODELO CNN (Completada)**
**Fecha:** 5 de febrero de 2026

#### 11.1 An√°lisis de Mejoras
Se realiz√≥ un an√°lisis t√©cnico del modelo CNN existente identificando oportunidades de optimizaci√≥n basadas en literatura reciente de deep learning. Las mejoras se documentaron en `docs/MEJORAS_MODELO.md`.

#### 11.2 Optimizaciones Implementadas en `models/cnn_geotermia.py`

| Optimizaci√≥n | Antes | Despu√©s | Justificaci√≥n |
|-------------|-------|---------|---------------|
| **SpatialDropout2D** | `Dropout` en bloques convolucionales | `SpatialDropout2D` | M√°s efectivo para datos espaciales; desactiva canales completos en vez de p√≠xeles individuales, preservando coherencia espacial |
| **AdamW** | `Adam` | `AdamW` (weight_decay=1e-4) | Separa la regularizaci√≥n L2 de la actualizaci√≥n de gradientes, mejorando la generalizaci√≥n |
| **Label Smoothing** | `BinaryCrossentropy()` | `BinaryCrossentropy(label_smoothing=0.1)` | Suaviza etiquetas duras (0/1 ‚Üí 0.05/0.95), reduciendo sobreconfianza y mejorando calibraci√≥n |
| **PR-AUC** | Solo AUC-ROC | + `AUC(curve='PR')` | M√°s informativo que ROC-AUC en datasets desbalanceados (77.5% positivos) |
| **F1Score** | Calculado manualmente | `F1Score` como m√©trica nativa | Monitoreo directo del balance precision-recall durante entrenamiento |
| **Cosine LR Decay** | No disponible | `get_cosine_decay_schedule()` | Learning rate decay suave sinusoidal, disponible como funci√≥n auxiliar |

**Verificaci√≥n:** Modelo compilado exitosamente ‚Äî 5,025,409 par√°metros, optimizer AdamW confirmado.

---

### **FASE 12: INTERFAZ GR√ÅFICA CON STREAMLIT (Completada)**
**Fecha:** 5 de febrero de 2026

#### 12.1 Desarrollo de la Aplicaci√≥n Web
Se desarroll√≥ una interfaz gr√°fica completa en `app.py` (674 l√≠neas) usando Streamlit, integrando visualizaci√≥n de datos geoespaciales y funcionalidades de predicci√≥n.

#### 12.2 P√°ginas Implementadas

| P√°gina | Funcionalidad |
|--------|---------------|
| **Inicio** | Descripci√≥n del proyecto, mapa interactivo de Colombia con zonas geot√©rmicas conocidas (Folium) |
| **Predicci√≥n** | Ingreso de coordenadas (latitud, longitud) ‚Üí predicci√≥n de potencial geot√©rmico con nivel de confianza |
| **M√©tricas** | Gr√°ficos interactivos de entrenamiento con Plotly (loss, accuracy, precision, recall) |
| **Arquitectura** | Diagrama visual de la arquitectura CNN con detalle de cada capa |
| **Acerca de** | Informaci√≥n del equipo, universidad, tecnolog√≠as y citaci√≥n acad√©mica |

#### 12.3 Tecnolog√≠as de la Interfaz
- **Streamlit** para el framework web.
- **Folium + streamlit-folium** para mapas interactivos.
- **Plotly** para gr√°ficos interactivos de m√©tricas.

**Ejecuci√≥n:**
```bash
streamlit run app.py --server.headless true
```

---

### **FASE 13: AUDITOR√çA Y LIMPIEZA DEL PROYECTO (Completada)**
**Fecha:** 9 de febrero de 2026

#### 13.1 Auditor√≠a Completa
Se realiz√≥ una revisi√≥n exhaustiva de todos los archivos del repositorio (39+ archivos) analizando:
- Redundancia entre archivos.
- Referencias cruzadas entre scripts y documentaci√≥n.
- Archivos hu√©rfanos (sin referencias).
- Oportunidades de consolidaci√≥n de documentaci√≥n.

#### 13.2 Archivos Eliminados

| Archivo | Raz√≥n de eliminaci√≥n |
|---------|---------------------|
| `verificar_config.py` | Funcionalidad duplicada con `setup.py` |
| `scripts/main.py` | Borrador inicial sin uso; reemplazado por `download_dataset.py` |
| `scripts/get_ee_project.py` | Script diagn√≥stico de 14 l√≠neas, cubierto por `setup.py` |
| `scripts/setup_earthengine.py` | Solo ejecutaba `ee.Authenticate()`; cubierto por `setup.py` |
| `scripts/fix_labels.py` | Script de uso √∫nico ya ejecutado; `augment_full_dataset.py` genera labels correctamente |
| `data/raw/*.tif.aux.xml` | Archivos auxiliares de GDAL auto-generados; no son c√≥digo fuente |

**Referencia actualizada:** `scripts/download_dataset.py` conten√≠a un mensaje de error que referenciaba `setup_earthengine.py` ‚Äî se actualiz√≥ para indicar `python -c "import ee; ee.Authenticate()"`.

#### 13.3 Documentaci√≥n Fusionada

Tres documentos con alto solapamiento informativo fueron fusionados en uno solo:

| Documentos originales | Documento resultante |
|----------------------|---------------------|
| `CONFIGURACION_COMPLETA.md` (383 l√≠neas) | `RESUMEN_PROYECTO.md` |
| `RESUMEN_EJECUTIVO.md` (428 l√≠neas) | (fusi√≥n de los 3) |
| `MONITOREO_ENTRENAMIENTO.md` (441 l√≠neas) | |

**Contenido preservado en `RESUMEN_PROYECTO.md`:**
- Estado general del proyecto y logros (de CONFIGURACION y RESUMEN).
- Historial de commits clave (de CONFIGURACION).
- Gu√≠a completa de monitoreo del entrenamiento (de MONITOREO).
- Configuraci√≥n de callbacks (de MONITOREO).
- Se√±ales de alerta durante entrenamiento (de MONITOREO).
- M√©tricas objetivo y problemas resueltos (de RESUMEN).
- Tecnolog√≠as, estructura del repositorio y equipo.

**Referencias actualizadas:**
- `docs/README.md` ‚Äî √çndice de documentos actualizado con el nuevo archivo.
- `docs/ENTRENAMIENTO_EXTERNO.md` ‚Äî Referencia de contacto actualizada.

#### 13.4 Archivos Reorganizados

| Archivo | Origen | Destino | Raz√≥n |
|---------|--------|---------|-------|
| `etiquetas_imagenesgeotermia.xlsx` | Ra√≠z del proyecto | `data/raw/` | Archivo de metadata del dataset; no era referenciado por ning√∫n script pero pertenece l√≥gicamente con los datos |

**Verificaci√≥n:** Ning√∫n script del proyecto le√≠a este archivo program√°ticamente. Se conserva como referencia hist√≥rica del etiquetado manual inicial.

#### 13.5 Actualizaci√≥n del `.gitignore`
Se agregaron las siguientes reglas para prevenir que archivos auxiliares auto-generados se incluyan en el repositorio:

```gitignore
# Archivos auxiliares de GDAL/QGIS (auto-generados)
*.tif.aux.xml
*.aux.xml
```

#### 13.6 Actualizaci√≥n del Registro de Proceso
Se actualiz√≥ `docs/REGISTRO_PROCESO.md` (este documento) con el registro detallado de todas las actividades realizadas desde febrero de 2026, incluyendo:
- Recuperaci√≥n del repositorio.
- Validaci√≥n del pipeline con mini-dataset.
- Optimizaciones del modelo.
- Desarrollo de la interfaz gr√°fica.
- Auditor√≠a y limpieza del proyecto.

---

### Fase 14: Configuraci√≥n Centralizada y Soporte Disco Externo (9 de febrero de 2026)

**Objetivo:** Permitir que el pipeline funcione con datos en disco externo (USB/SSD) para entrenar en los computadores de la universidad sin depender de espacio local.

#### 14.1 Nuevo archivo `config.py`
- Configuraci√≥n centralizada de todas las rutas del proyecto.
- Variable de entorno `GEOTERMIA_DATA_ROOT` para apuntar a disco externo.
- M√©todo `validate()` para verificar estado de carpetas.
- Hiperpar√°metros centralizados (batch_size, epochs, lr, etc.).

#### 14.2 Scripts actualizados para usar `config.py`
- `scripts/download_dataset.py` ‚Üí usa `cfg.raw_dir`
- `scripts/augment_full_dataset.py` ‚Üí usa `cfg.raw_dir` y `cfg.augmented_dir`
- `scripts/prepare_dataset.py` ‚Üí usa `cfg.augmented_dir` y `cfg.processed_dir`
- `scripts/train_model.py` ‚Üí usa `cfg.processed_dir` y `cfg.models_dir`

#### 14.3 Script obsoleto eliminado
- `scripts/augment_dataset.py`: Script de prueba inicial con solo 3 im√°genes hardcoded de `geotermia_imagenes/`. Reemplazado completamente por `augment_full_dataset.py`.

#### 14.4 Actualizaciones de documentaci√≥n y dependencias
- `requirements.txt`: TF ‚â•2.20.0, agregado streamlit/streamlit-folium/fpdf2, eliminado keras separado y PyPDF2.
- `setup.py`: Actualizado check de Python ‚â•3.10, siguiente paso apunta a `config.py`.
- `README.md`: √Årbol de estructura actualizado con `config.py` y todos los scripts.
- `MODELO_PREDICTIVO.md`: TF 2.20+ / Keras 3.x.
- `ENTRENAMIENTO_EXTERNO.md`: Branch corregido a `main`, agregada opci√≥n de disco externo.
- `app.py`: Corregido `use_container_width` deprecado en `st.image()` ‚Üí `width="stretch"`.

---

## üìä ESTAD√çSTICAS DEL PROYECTO

### Dataset
- **Im√°genes originales descargadas:** 85
- **Im√°genes despu√©s de augmentaci√≥n:** 5,518
- **Factor de aumento:** 64.9x
- **Tama√±o total procesado:** ~2.5 GB
- **Bandas espectrales por imagen:** 5 (ASTER t√©rmico)
- **Resoluci√≥n final:** 224x224 p√≠xeles

### Modelo
- **Arquitectura:** CNN personalizada ResNet-inspired
- **Capas totales:** 52
- **Par√°metros entrenables:** 5,025,409
- **Input shape:** (224, 224, 5)
- **Output:** Clasificaci√≥n binaria (sigmoid)

### Distribuci√≥n de Datos
```
Training:    3,862 im√°genes (70%)
Validation:    828 im√°genes (15%)
Test:          828 im√°genes (15%)
Total:       5,518 im√°genes (100%)

Balance de clases:
  Positivo (geot√©rmico): 77.5%
  Negativo (control):    22.5%
```

---

## üõ†Ô∏è TECNOLOG√çAS UTILIZADAS

### Framework de Deep Learning
- **TensorFlow:** 2.20.0
- **Keras:** 3.12.0

### Procesamiento de Datos
- **NumPy:** 2.2.6
- **pandas:** √∫ltima versi√≥n
- **scikit-learn:** 1.7.2
- **scikit-image:** 0.25.2
- **opencv-python:** 4.12.0
- **scipy:** 1.15.3

### Datos Geoespaciales
- **rasterio:** Lectura de GeoTIFF
- **earthengine-api:** Google Earth Engine
- **Dataset:** NASA ASTER GED AG100_003

### Visualizaci√≥n e Interfaz
- **matplotlib:** Gr√°ficos est√°ticos
- **seaborn:** Visualizaciones estad√≠sticas
- **TensorBoard:** Monitoreo de entrenamiento
- **Plotly:** Gr√°ficos interactivos de m√©tricas
- **Streamlit:** Framework web para la interfaz gr√°fica
- **Folium / streamlit-folium:** Mapas interactivos

### Reportes
- **FPDF2:** Generaci√≥n de reportes en PDF

### Control de Versiones
- **Git:** Control de versiones
- **GitHub:** Repositorio remoto

---

## üìà RESULTADOS ESPERADOS

### Objetivos de Performance
- **Accuracy m√≠nima esperada:** 85%
- **Precision objetivo:** >80% para ambas clases
- **Recall objetivo:** >80% para ambas clases
- **F1-Score objetivo:** >0.80
- **AUC objetivo:** >0.90

### Aplicaci√≥n Pr√°ctica
El modelo entrenado podr√°:
1. Identificar zonas con potencial geot√©rmico en Colombia
2. Diferenciar entre zonas volc√°nicas activas y zonas de control
3. Procesar im√°genes satelitales ASTER de 5 bandas t√©rmicas
4. Proporcionar probabilidades de confianza en las predicciones
5. Servir como herramienta de apoyo para exploraci√≥n geot√©rmica

---

## üîÑ PR√ìXIMOS PASOS

1. ‚è≥ **Completar entrenamiento del modelo en GPU** (RTX 5070 objetivo, 100 √©pocas)
2. ‚è≥ **Evaluar performance en test set** (828 im√°genes)
3. ‚è≥ **Generar visualizaciones de alta calidad** (300 DPI para tesis)
4. ‚è≥ **Documentar resultados finales**
5. ‚è≥ **Preparar presentaci√≥n para sustentaci√≥n de tesis**
6. ‚è≥ **Considerar dataset extendido** (50-100 GB con TFRecords en disco externo)

---

## üë• EQUIPO

**Estudiantes:**
- Cristian Camilo Vega S√°nchez (Lead Developer)
- Daniel Santiago Ar√©valo Rubiano
- Yuliet Katerin Espitia Ayala
- Laura Sophie Rivera Martin

**Asesor Acad√©mico:**
- Prof. Yeison Eduardo Conejo Sandoval

**Instituci√≥n:**
- Universidad de San Buenaventura - Bogot√°
- Facultad de Ingenier√≠a
- Programa de Ingenier√≠a de Sistemas

---

## üìù NOTAS T√âCNICAS

### Consideraciones Importantes

1. **Balance de Clases:**
   - Se aplicaron pesos de clase para compensar desbalance
   - Data augmentation m√°s agresiva en clase minoritaria

2. **Validaci√≥n Cruzada:**
   - Divisi√≥n estratificada mantiene proporci√≥n de clases
   - Random state fijo (42) garantiza reproducibilidad

3. **Optimizaciones de Hardware:**
   - CPU con instrucciones SIMD habilitadas
   - Mixed precision para acelerar entrenamiento
   - Batch size optimizado para memoria disponible

4. **Prevenci√≥n de Overfitting:**
   - Dropout layers en arquitectura
   - Early stopping con patience=15
   - Data augmentation en tiempo real
   - Regularizaci√≥n L2 en capas densas

5. **Monitoreo:**
   - TensorBoard para seguimiento en tiempo real
   - CSVLogger para an√°lisis posterior
   - Checkpoints autom√°ticos del mejor modelo

---

**√öltima actualizaci√≥n:** 9 de febrero de 2026  
**Estado del proyecto:** Fase 14 completada ‚Äî Configuraci√≥n centralizada y soporte disco externo  
**Pr√≥xima revisi√≥n:** Al completar entrenamiento en GPU
